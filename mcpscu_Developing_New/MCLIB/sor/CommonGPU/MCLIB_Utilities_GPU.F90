!
!  MCLIB_Utilities_GPU.F90
!
!  Free-Format Fortran Source File
!  Generated by PGI Visual Fortran(R)
!  10/17/2017 10:06:52 PM
module MCLIB_Utilities_GPU
  use cudafor
  use curand_device
  use MCLIB_CONSTANTS_GPU
  use MCLIB_UTILITIES_FORMER
  use MCLIB_TYPEDEF_ACLUSTER
  use MCLIB_TYPEDEF_GEOMETRY
  use MCLIB_TYPEDEF_NEIGHBOR_LIST
  use CudaRandomC2F_M
  #ifdef MC_PROFILING
  use MCLIB_TimeProfile
  #endif
  implicit none

  integer,private,parameter::p_BLOCKSIZE_BITONIC = 256

  integer,parameter::p_Sort_Descending = 0
  integer,parameter::p_Sort_Ascending = 1

  INTERFACE Assignment (=)
    MODULE PROCEDURE CopyClusterFromOther_Dev
  END INTERFACE

  !-----------------------
  interface AllocateArray_GPU
    MODULE PROCEDURE AllocateOneDimi_GPU
    MODULE PROCEDURE AllocateOneDimr_GPU
    MODULE PROCEDURE AllocateOneDimd_GPU
    MODULE PROCEDURE AllocateOneDimACluster_GPU


    MODULE PROCEDURE AllocateTwoDimi_GPU
    MODULE PROCEDURE AllocateTwoDimr_GPU
    MODULE PROCEDURE AllocateTwoDimd_GPU
    MODULE PROCEDURE AllocateTwoDimACluster_GPU

    MODULE PROCEDURE AllocateThreeDimi_GPU
    MODULE PROCEDURE AllocateThreeDimr_GPU
    MODULE PROCEDURE AllocateThreeDimd_GPU

  end interface AllocateArray_GPU

  !------------------
  interface DeAllocateArray_GPU
    MODULE PROCEDURE DeAllocateOneDimi_GPU
    MODULE PROCEDURE DeAllocateOneDimr_GPU
    MODULE PROCEDURE DeAllocateOneDimd_GPU
    MODULE PROCEDURE DeAllocateOneDimACluster_GPU

    MODULE PROCEDURE DeAllocateTwoDimi_GPU
    MODULE PROCEDURE DeAllocateTwoDimr_GPU
    MODULE PROCEDURE DeAllocateTwoDimd_GPU
    MODULE PROCEDURE DeAllocateTwoDimACluster_GPU

    MODULE PROCEDURE DeAllocateThreeDimi_GPU
    MODULE PROCEDURE DeAllocateThreeDimr_GPU
    MODULE PROCEDURE DeAllocateThreeDimd_GPU

  end interface DeAllocateArray_GPU

  type,public::BitionicSort
	integer,dimension(:,:),allocatable::IDStartEnd_ForSort_Host
	integer,device,dimension(:,:),allocatable::IDStartEnd_ForSort_Dev
	integer,device,dimension(:),allocatable::OEFlags_Dev
	integer,device,dimension(:),allocatable::SortedIndex_Dev
	integer::MaxSegmentsNumEachBox = 0
	integer::MaxSegmentsNumAllBox = 0
	integer::MaxClusterNumEachBox = 0
	type(dim3)::blocksGlobal
	type(dim3)::threadsGlobal
	type(dim3)::blocksShared
    type(dim3)::threadsShared
    integer::dir = p_Sort_Ascending
    real(kind=KINDDF)::padNum = 1.D32
    logical::HasInitedFlag = .false.

    contains
    procedure,public,non_overridable,pass::Init=>InitBitionicSort
    procedure,public,non_overridable,pass::Sort=>ArbitraryBitonicSort_toApply
    procedure,public,non_overridable,pass::Clean=>Clean_BitionicSort
    Final::CleanBitionicSort
  end type BitionicSort

  private::ArbitraryBitonicSort_toApply

  contains

  attributes(device) subroutine CopyClusterFromOther_Dev(Dist,Source)
    implicit none
    !---Dummy Vars---
    type(ACluster),intent(out)::Dist
    type(ACluster),intent(in)::Source
    !---Local Vars---
    integer::IElement
    !---Body---
    DO IElement = 1,p_ATOMS_GROUPS_NUMBER
        Dist%m_Atoms(IElement) = Source%m_Atoms(IElement)
    END DO

    Dist%m_POS = Source%m_POS

    Dist%m_RAD = Source%m_RAD

    Dist%m_Layer = Source%m_Layer

    Dist%m_Statu = Source%m_Statu

    Dist%m_GrainID = Source%m_GrainID

    Dist%m_DiffCoeff = Source%m_DiffCoeff

    Dist%m_DiffuseDirection = Source%m_DiffuseDirection

    Dist%m_Record = Source%m_Record

    return
  end subroutine

  !****************************************************
  subroutine Get_DeviceMemInfo(FreeMemSize,TotalMemSize)
    implicit none
    !---Dummy Vars---
    integer(kind=cuda_count_kind)::FreeMemSize
    integer(kind=cuda_count_kind)::TotalMemSize
    !---Local Vars---
    integer::err
    !---Body----
    err = cudaMemGetInfo(FreeMemSize,TotalMemSize)

    return
  end subroutine Get_DeviceMemInfo


  !*************************************************************
  subroutine AllocateOneDimi_GPU(Array,Length,Name)
    implicit none
    !---Dummy Vars---
    integer,device,dimension(:),allocatable::Array
    integer,intent(in)::Length
    character(*)::Name
    !---Dummy Vars---
    integer::istat
    !---Body---
    call DeAllocateOneDimi_GPU(Array,Name)

    if(Length .GT. 0) then
        allocate(Array(Length),STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"allocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine AllocateOneDimi_GPU

  !*************************************************************
  subroutine AllocateOneDimr_GPU(Array,Length,Name)
    implicit none
    !---Dummy Vars---
    real(kind=KINDSF),device,dimension(:),allocatable::Array
    integer,intent(in)::Length
    character(*)::Name
    !---Dummy Vars---
    integer::istat
    !---Body---
    call DeAllocateOneDimr_GPU(Array,Name)

    if(Length .GT. 0) then
        allocate(Array(Length),STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"allocate Failed !"
            pause
            stop
         end if
    end if

    return
  end subroutine AllocateOneDimr_GPU

  !*************************************************************
  subroutine AllocateOneDimd_GPU(Array,Length,Name)
    implicit none
    !---Dummy Vars---
    real(kind=KINDDF),device,dimension(:),allocatable::Array
    integer,intent(in)::Length
    character(*)::Name
    !---Dummy Vars---
    integer::istat
    !---Body---
    call DeAllocateOneDimd_GPU(Array,Name)

    if(Length .GT. 0) then
        allocate(Array(Length),STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"allocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine AllocateOneDimd_GPU

  !*************************************************************
  subroutine AllocateOneDimACluster_GPU(Array,Length,Name)
    implicit none
    !---Dummy Vars---
    type(ACluster),device,dimension(:),allocatable::Array
    integer,intent(in)::Length
    character(*)::Name
    !---Dummy Vars---
    integer::istat
    !---Body---
    call DeAllocateOneDimACluster_GPU(Array,Name)

    if(Length .GT. 0) then
        allocate(Array(Length),STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"allocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine AllocateOneDimACluster_GPU

  !*************************************************************
  subroutine AllocateTwoDimi_GPU(Array,LengthX,LengthY,Name)
    implicit none
    !---Dummy Vars---
    integer,device,dimension(:,:),allocatable::Array
    integer,intent(in)::LengthX
    integer,intent(in)::LengthY
    character(*)::Name
    !---Dummy Vars---
    integer::istat
    !---Body---
    call DeAllocateTwoDimi_GPU(Array,Name)

    if(LengthX .GT. 0 .AND. LengthY .GT. 0) then
        allocate(Array(LengthX,LengthY),STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"allocate Failed !"
            pause
            stop
         end if
    end if

    return
  end subroutine AllocateTwoDimi_GPU

  !*************************************************************
  subroutine AllocateTwoDimr_GPU(Array,LengthX,LengthY,Name)
    implicit none
    !---Dummy Vars---
    real(kind=KINDSF),device,dimension(:,:),allocatable::Array
    integer,intent(in)::LengthX
    integer,intent(in)::LengthY
    character(*)::Name
    !---Dummy Vars---
    integer::istat
    !---Body---
    call DeAllocateTwoDimr_GPU(Array,Name)

    if(LengthX .GT. 0 .AND. LengthY .GT. 0) then
        allocate(Array(LengthX,LengthY),STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"allocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine AllocateTwoDimr_GPU

  !*************************************************************
  subroutine AllocateTwoDimd_GPU(Array,LengthX,LengthY,Name)
    implicit none
    !---Dummy Vars---
    real(kind=KINDDF),device,dimension(:,:),allocatable::Array
    integer,intent(in)::LengthX
    integer,intent(in)::LengthY
    character(*)::Name
    !---Dummy Vars---
    integer::istat
    !---Body---
    call DeAllocateTwoDimd_GPU(Array,Name)

    if(LengthX .GT. 0 .AND. LengthY .GT. 0) then
        allocate(Array(LengthX,LengthY),STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"allocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine AllocateTwoDimd_GPU

  !*************************************************************
  subroutine AllocateTwoDimACluster_GPU(Array,LengthX,LengthY,Name)
    implicit none
    !---Dummy Vars---
    type(ACluster),device,dimension(:,:),allocatable::Array
    integer,intent(in)::LengthX
    integer,intent(in)::LengthY
    character(*)::Name
    !---Dummy Vars---
    integer::istat
    !---Body---
    call DeAllocateTwoDimACluster_GPU(Array,Name)

    if(LengthX .GT. 0 .AND. LengthY .GT. 0) then
        allocate(Array(LengthX,LengthY),STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"allocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine AllocateTwoDimACluster_GPU


  !*************************************************************
  subroutine AllocateThreeDimi_GPU(Array,LengthX,LengthY,LengthZ,Name)
    implicit none
    !---Dummy Vars---
    integer,device,dimension(:,:,:),allocatable::Array
    integer,intent(in)::LengthX
    integer,intent(in)::LengthY
    integer,intent(in)::LengthZ
    character(*)::Name
    !---Dummy Vars---
    integer::istat
    !---Body---
    call DeAllocateThreeDimi_GPU(Array,Name)

    if(LengthX .GT. 0 .AND. LengthY .GT. 0 .AND. LengthZ .GT. 0) then
        allocate(Array(LengthX,LengthY,LengthZ),STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"allocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine AllocateThreeDimi_GPU

  !*************************************************************
  subroutine AllocateThreeDimr_GPU(Array,LengthX,LengthY,LengthZ,Name)
    implicit none
    !---Dummy Vars---
    real(kind=KINDSF),device,dimension(:,:,:),allocatable::Array
    integer,intent(in)::LengthX
    integer,intent(in)::LengthY
    integer,intent(in)::LengthZ
    character(*)::Name
    !---Dummy Vars---
    integer::istat
    !---Body---
    call DeAllocateThreeDimr_GPU(Array,Name)

    if(LengthX .GT. 0 .AND. LengthY .GT. 0 .AND. LengthZ .GT. 0) then
        allocate(Array(LengthX,LengthY,LengthZ),STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"allocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine AllocateThreeDimr_GPU

  !*************************************************************
  subroutine AllocateThreeDimd_GPU(Array,LengthX,LengthY,LengthZ,Name)
    implicit none
    !---Dummy Vars---
    real(kind=KINDDF),device,dimension(:,:,:),allocatable::Array
    integer,intent(in)::LengthX
    integer,intent(in)::LengthY
    integer,intent(in)::LengthZ
    character(*)::Name
    !---Dummy Vars---
    integer::istat
    !---Body---
    call DeAllocateThreeDimd_GPU(Array,Name)

    if(LengthX .GT. 0 .AND. LengthY .GT. 0 .AND. LengthZ .GT. 0) then
        allocate(Array(LengthX,LengthY,LengthZ),STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"allocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine AllocateThreeDimd_GPU

  !*************************************************************
  subroutine DeAllocateOneDimi_GPU(Array,Name)
    implicit none
    !---Dummy Vars---
    integer,device,dimension(:),allocatable::Array
    character(*)::Name
    !---Local Vars---
    integer::istat
    !---Body---

    if(allocated(Array)) then
        deallocate(Array,STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"Deallocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine DeAllocateOneDimi_GPU


  !*************************************************************
  subroutine DeAllocateOneDimr_GPU(Array,Name)
    implicit none
    !---Dummy Vars---
    real(kind=KINDSF),device,dimension(:),allocatable::Array
    character(*)::Name
    !---Local Vars---
    integer::istat
    !---Body---

    if(allocated(Array)) then
        deallocate(Array,STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"Deallocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine DeAllocateOneDimr_GPU

  !*************************************************************
  subroutine DeAllocateOneDimd_GPU(Array,Name)
    implicit none
    !---Dummy Vars---
    real(kind=KINDDF),device,dimension(:),allocatable::Array
    character(*)::Name
    !---Local Vars---
    integer::istat
    !---Body---

    if(allocated(Array)) then
        deallocate(Array,STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"Deallocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine DeAllocateOneDimd_GPU

  !*************************************************************
  subroutine DeAllocateOneDimACluster_GPU(Array,Name)
    implicit none
    !---Dummy Vars---
    type(ACluster),device,dimension(:),allocatable::Array
    character(*)::Name
    !---Local Vars---
    integer::istat
    !---Body---

    if(allocated(Array)) then
        deallocate(Array,STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"Deallocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine DeAllocateOneDimACluster_GPU

  !*************************************************************
  subroutine DeAllocateTwoDimi_GPU(Array,Name)
    implicit none
    !---Dummy Vars---
    integer,device,dimension(:,:),allocatable::Array
    character(*)::Name
    !---Local Vars---
    integer::istat
    !---Body---

    if(allocated(Array)) then
        deallocate(Array,STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"Deallocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine DeAllocateTwoDimi_GPU

  !*************************************************************
  subroutine DeAllocateTwoDimr_GPU(Array,Name)
    implicit none
    !---Dummy Vars---
    real(kind=KINDSF),device,dimension(:,:),allocatable::Array
    character(*)::Name
    !---Local Vars---
    integer::istat
    !---Body---

    if(allocated(Array)) then
        deallocate(Array,STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"Deallocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine DeAllocateTwoDimr_GPU

  !*************************************************************
  subroutine DeAllocateTwoDimd_GPU(Array,Name)
    implicit none
    !---Dummy Vars---
    real(kind=KINDDF),device,dimension(:,:),allocatable::Array
    character(*)::Name
    !---Local Vars---
    integer::istat
    !---Body---

    if(allocated(Array)) then
        deallocate(Array,STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"Deallocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine DeAllocateTwoDimd_GPU

  !*************************************************************
  subroutine DeAllocateTwoDimACluster_GPU(Array,Name)
    implicit none
    !---Dummy Vars---
    type(ACluster),device,dimension(:,:),allocatable::Array
    character(*)::Name
    !---Local Vars---
    integer::istat
    !---Body---

    if(allocated(Array)) then
        deallocate(Array,STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"Deallocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine DeAllocateTwoDimACluster_GPU



  !*************************************************************
  subroutine DeAllocateThreeDimi_GPU(Array,Name)
    implicit none
    !---Dummy Vars---
    integer,device,dimension(:,:,:),allocatable::Array
    character(*)::Name
    !---Local Vars---
    integer::istat
    !---Body---

    if(allocated(Array)) then
        deallocate(Array,STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"Deallocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine DeAllocateThreeDimi_GPU

  !*************************************************************
  subroutine DeAllocateThreeDimr_GPU(Array,Name)
    implicit none
    !---Dummy Vars---
    real(kind=KINDSF),device,dimension(:,:,:),allocatable::Array
    character(*)::Name
    !---Local Vars---
    integer::istat
    !---Body---

    if(allocated(Array)) then
        deallocate(Array,STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"Deallocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine DeAllocateThreeDimr_GPU

  !*************************************************************
  subroutine DeAllocateThreeDimd_GPU(Array,Name)
    implicit none
    !---Dummy Vars---
    real(kind=KINDDF),device,dimension(:,:,:),allocatable::Array
    character(*)::Name
    !---Local Vars---
    integer::istat
    !---Body---

    if(allocated(Array)) then
        deallocate(Array,STAT=istat)
        if(istat /=0) then
            write(*,*) "MCPSCUERROR: The Array :",Name,"Deallocate Failed !"
            pause
            stop
        end if
    end if

    return
  end subroutine DeAllocateThreeDimd_GPU

  !**********************************************************************
  attributes(device) function BinarySearch_GE_DEV(InputNum,DimensionX,TheArray,IndexX,LeftBound,RightBound) result(ResultIndex)
    implicit none
    !---Dummy Vars---
    integer,value,intent(in)::InputNum
    integer,value::DimensionX
    integer,device::TheArray(DimensionX,*) ! When the nollvm compiler option is used, the attributes(device) dummy vars array should write as (x,*) for two dimension, cannot be (:,:)
    integer,value::IndexX
    integer,value,intent(in)::LeftBound
    integer,value,intent(in)::RightBound
    integer,value,intent(out)::ResultIndex
    !---Local Vars---
    integer::ILeft,IRight,IMiddle
    !---Body---
    ResultIndex = -1

    ILeft = LeftBound
    IRight = RightBound

    DO While(ILeft .LE. IRight)

        IMiddle = (ILeft+IRight)/2

        if(InputNum .LE. TheArray(IndexX,IMiddle)) then
            if(IMiddle .eq. LeftBound .or. InputNum .GT. TheArray(IndexX,IMiddle-1) ) then
                ResultIndex = IMiddle
                exit
            else
                IRight = IMiddle - 1
                cycle
            end if
        else
            ILeft = IMiddle + 1
        end if

    END DO

    return
  end function BinarySearch_GE_DEV

  !*****************************************************
  attributes(device) function BinarySearch_EQ_DEV(InputNum,TheArray,LeftBound,RightBound) result(ResultIndex)
    implicit none
    !---Dummy Vars---
    integer,value,intent(in)::InputNum
    integer,device::TheArray(*) ! When the nollvm compiler option is used, the attributes(device) dummy vars array should write as (*) for one dimension,cannot be (:)
    integer,value,intent(in)::LeftBound
    integer,value,intent(in)::RightBound
    integer,value,intent(out)::ResultIndex
    !---Local Vars---
    integer::ILeft,IRight,IMiddle
    !---Body---
    ResultIndex = -1

    ILeft = LeftBound
    IRight = RightBound

    DO While(ILeft .LE. IRight)
        IMiddle = (ILeft+IRight)/2

        if(InputNum .LT. TheArray(IMiddle)) then
            IRight = IMiddle - 1
        else if(InputNum .GT. TheArray(IMiddle)) then
            ILeft = IMiddle + 1
        else
            ResultIndex = IMiddle
            exit
        end if

    END DO

    return
  end function BinarySearch_EQ_DEV

  !********************************************************
  attributes(device) subroutine BinarySearchBoxIndex(MultiBox,SearchIndex,Dev_SEIndexBox,ResultBoxIndex)
    implicit none
    !---Dummy Vars---
    integer, value::MultiBox
    integer, value::SearchIndex
    integer, device, dimension(MultiBox,2)::Dev_SEIndexBox
    integer,intent(out)::ResultBoxIndex
    !---Local Vars---
    integer::I,ILeft,IRight,IMiddle
    !---Body---
    ILeft = 1
    IRight = MultiBox
    IMiddle = (ILeft+IRight)/2

    DO I = 1,MultiBox
        if(Dev_SEIndexBox(IMiddle,1) .GT. SearchIndex) then
            IRight = IMiddle
            IMiddle = (ILeft + IMiddle)/2
            cycle
        else if(Dev_SEIndexBox(IMiddle,1) .LT. SearchIndex) then
            if(Dev_SEIndexBox(IMiddle,2) .GE. SearchIndex) then
                ResultBoxIndex = IMiddle
                exit
            else if(Dev_SEIndexBox(IMiddle,2) .LT. SearchIndex) then
              if(Dev_SEIndexBox(IMiddle+1,2) .GE. SearchIndex) then
                ResultBoxIndex = IMiddle + 1
                exit
              end if
              ILeft = IMiddle
              IMiddle = (IMiddle + IRight)/2
              cycle
            end if
        else
            ResultBoxIndex = IMiddle
            exit
        end if
    END DO

    ResultBoxIndex = min(ResultBoxIndex,MultiBox)

    return
  end subroutine BinarySearchBoxIndex

  !********************************************************
  attributes(device) subroutine BinarySearchBoxIndex2(MultiBox,SearchIndex,Dev_StartIndexBox,ResultBoxIndex)
    implicit none
    !---Dummy Vars---
    integer, value::MultiBox
    integer, value::SearchIndex
    integer, device, dimension(MultiBox)::Dev_StartIndexBox
    integer, intent(out)::ResultBoxIndex
    !---Local Vars---
    integer::I,ILeft,IRight,IMiddle
    !---Body---
    ResultBoxIndex = 1
    ILeft = 1
    IRight = MultiBox
    IMiddle = (ILeft+IRight)/2
    DO I = 1,MultiBox-1
        if(Dev_StartIndexBox(IMiddle) .GT. SearchIndex) then
            IRight = IMiddle
            IMiddle = (ILeft + IRight)/2
            cycle
        else if(Dev_StartIndexBox(IMiddle+1) .GT. SearchIndex) then
            ResultBoxIndex = IMiddle
            exit
        else if(IMiddle .eq. (MultiBox -1)) then
            ResultBoxIndex = MultiBox
            exit
        end if
        ILeft = IMiddle
        IMiddle = (IMiddle + IRight)/2
    END DO


  end subroutine BinarySearchBoxIndex2

  !*****************************************************************
  subroutine copyClustersDevToDevSync(Source_Clusters,Dest_Clusters,NC)
    implicit none
    !---Dummy Vars---
    type(ACluster),device,dimension(:),allocatable,target::Source_Clusters
    type(ACluster),device,dimension(:),allocatable::Dest_Clusters
    integer::NC
    !---Local Vars---
    type(C_DEVPTR)::SrP_Clusters
    type(C_DEVPTR)::DestP_Cluster
    integer::err
    !---Body---
    SrP_Clusters = c_devloc(Source_Clusters)
    DestP_Cluster = c_devloc(Dest_Clusters)


        if(NC .GT. size(Source_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of source clusters:",size(Source_Clusters), &
                    "less than the copy clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(Dest_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of destination clusters:",size(Dest_Clusters), &
                    "less than the copy clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if


    err = cudaMemCpy(DestP_Cluster,SrP_Clusters,NC*Get_MemoryConsuming_ClusterType(),cudaMemcpyDeviceToDevice)

    return
  end subroutine copyClustersDevToDevSync

  !*****************************************************************
  subroutine copyClustersDevToDevSync2D(Source_Clusters,Dest_Clusters,NC)
    implicit none
    !---Dummy Vars---
    type(ACluster),device,dimension(:,:),allocatable,target::Source_Clusters
    type(ACluster),device,dimension(:,:),allocatable::Dest_Clusters
    integer::NC
    !---Local Vars---
    type(C_DEVPTR)::SrP_Clusters
    type(C_DEVPTR)::DestP_Cluster
    integer::err
    !---Body---
    SrP_Clusters = c_devloc(Source_Clusters)
    DestP_Cluster = c_devloc(Dest_Clusters)


        if(NC .GT. size(Source_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of source clusters:",size(Source_Clusters), &
                    "less than the copy clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(Dest_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of destination clusters:",size(Dest_Clusters), &
                    "less than the copy clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if


    err = cudaMemCpy(DestP_Cluster,SrP_Clusters,NC*Get_MemoryConsuming_ClusterType(),cudaMemcpyDeviceToDevice)

    return
  end subroutine copyClustersDevToDevSync2D

  !*****************************************************************
  subroutine copyClustersDevToDevAsync(Source_Clusters,Dest_Clusters)
    implicit none
    !---Dummy Vars---
    type(ACluster),device,dimension(:),allocatable,target::Source_Clusters
    type(ACluster),device,dimension(:),allocatable::Dest_Clusters
    integer::NC
    !---Local Vars---
    type(C_DEVPTR)::SrP_Clusters
    type(C_DEVPTR)::DestP_Cluster
    integer::err
    !---Body---
    SrP_Clusters = c_devloc(Source_Clusters)
    DestP_Cluster = c_devloc(Dest_Clusters)


        if(NC .GT. size(Source_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of source clusters:",size(Source_Clusters), &
                    "less than the copy clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(Dest_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of destination clusters:",size(Dest_Clusters), &
                    "less than the copy clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if


    err = cudaMemCpyAsync(DestP_Cluster,SrP_Clusters,NC*Get_MemoryConsuming_ClusterType(),cudaMemcpyDeviceToDevice)

    return
  end subroutine copyClustersDevToDevAsync

  !*****************************************************************
  subroutine copyClustersDevToDevAsync2D(Source_Clusters,Dest_Clusters)
    implicit none
    !---Dummy Vars---
    type(ACluster),device,dimension(:,:),allocatable,target::Source_Clusters
    type(ACluster),device,dimension(:,:),allocatable::Dest_Clusters
    integer::NC
    !---Local Vars---
    type(C_DEVPTR)::SrP_Clusters
    type(C_DEVPTR)::DestP_Cluster
    integer::err
    !---Body---
    SrP_Clusters = c_devloc(Source_Clusters)
    DestP_Cluster = c_devloc(Dest_Clusters)


        if(NC .GT. size(Source_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of source clusters:",size(Source_Clusters), &
                    "less than the copy clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(Dest_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of destination clusters:",size(Dest_Clusters), &
                    "less than the copy clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if


    err = cudaMemCpyAsync(DestP_Cluster,SrP_Clusters,NC*Get_MemoryConsuming_ClusterType(),cudaMemcpyDeviceToDevice)

    return
  end subroutine copyClustersDevToDevAsync2D

  !*****************************************************************
  subroutine copyInClustersSync(HOST_Clusters,DEV_Clusters,NC)
    !***  PURPOSE:  to copy the Clusters From Host to Device(Sychronize)
    !     INPUT:    HOST_Clusters, the clusters array in host
    !               DEV_Clusters , the clusters array in device
    !               NC           , the number of clusters that need to copy
    implicit none
    !---Dummy vars---
    type(Acluster),dimension(:),allocatable,target::HOST_Clusters
    type(Acluster),device,dimension(:),allocatable::DEV_Clusters
    integer::NC
    !---Local Vars---
    integer::err
    type(C_PTR)::hp_Clusters
    type(C_DEVPTR)::dp_Clusters

    #ifdef MC_PROFILING
    call Time_Start(T_copyInClustersSync_Start)
    #endif
    !---Body---

    if(NC .GT. size(HOST_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of host clusters:",size(HOST_Clusters), &
                    "less than the copyin clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(DEV_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of device clusters:",size(DEV_Clusters), &
                    "less than the copyin clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    ! Way 1
    !DEV_Clusters = HOST_Clusters

    ! Way 2
    hp_Clusters = c_loc(HOST_Clusters)
    dp_Clusters = c_devloc(DEV_Clusters)
    err = cudaMemcpy(dp_Clusters,hp_Clusters,NC*Get_MemoryConsuming_ClusterType())

    #ifdef MC_PROFILING
    call Time_Accumulate(T_copyInClustersSync_Start,T_copyInClustersSync)
    #endif
    return
  end subroutine copyInClustersSync

  !*****************************************************************
  subroutine copyInClustersSync2D(HOST_Clusters,DEV_Clusters,NC)
    !***  PURPOSE:  to copy the Clusters From Host to Device(Sychronize)
    !     INPUT:    HOST_Clusters, the clusters array in host
    !               DEV_Clusters , the clusters array in device
    !               NC           , the number of clusters that need to copy
    implicit none
    !---Dummy vars---
    type(Acluster),dimension(:,:),allocatable,target::HOST_Clusters
    type(Acluster),device,dimension(:,:),allocatable::DEV_Clusters
    integer::NC
    !---Local Vars---
    integer::err
    type(C_PTR)::hp_Clusters
    type(C_DEVPTR)::dp_Clusters

    #ifdef MC_PROFILING
    call Time_Start(T_copyInClustersSync_Start)
    #endif
    !---Body---

    if(NC .GT. size(HOST_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of host clusters:",size(HOST_Clusters), &
                    "less than the copyin clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(DEV_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of device clusters:",size(DEV_Clusters), &
                    "less than the copyin clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    ! Way 1
    !DEV_Clusters = HOST_Clusters

    ! Way 2
    hp_Clusters = c_loc(HOST_Clusters)
    dp_Clusters = c_devloc(DEV_Clusters)
    err = cudaMemcpy(dp_Clusters,hp_Clusters,NC*Get_MemoryConsuming_ClusterType())

    #ifdef MC_PROFILING
    call Time_Accumulate(T_copyInClustersSync_Start,T_copyInClustersSync)
    #endif
    return
  end subroutine copyInClustersSync2D

  !*****************************************************************
  subroutine copyInClustersAsync(HOST_Clusters,DEV_Clusters,NC)
    !***  PURPOSE:  to copy the Clusters From Host to Device(Async)
    !     INPUT:    HOST_Clusters, the clusters array in host
    !               DEV_Clusters , the clusters array in device
    !               NC           , the number of clusters that need to copy
    implicit none
    !---Dummy vars---
    type(Acluster),dimension(:),allocatable,target::HOST_Clusters
    type(Acluster),device,dimension(:),allocatable::DEV_Clusters
    integer::NC
    !---Local Vars---
    integer::err
    type(C_PTR)::hp_Clusters
    type(C_DEVPTR)::dp_Clusters

    !---Body---


    if(NC .GT. size(HOST_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of host clusters:",size(HOST_Clusters), &
                    "less than the copyin clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(DEV_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of device clusters:",size(DEV_Clusters), &
                    "less than the copyin clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    hp_Clusters = c_loc(HOST_Clusters)
    dp_Clusters = c_devloc(DEV_Clusters)
    err = cudaMemcpyAsync(dp_Clusters,hp_Clusters,NC*Get_MemoryConsuming_ClusterType())

    return
  end subroutine copyInClustersAsync

  !*****************************************************************
  subroutine copyInClustersAsync2D(HOST_Clusters,DEV_Clusters,NC)
    !***  PURPOSE:  to copy the Clusters From Host to Device(Async)
    !     INPUT:    HOST_Clusters, the clusters array in host
    !               DEV_Clusters , the clusters array in device
    !               NC           , the number of clusters that need to copy
    implicit none
    !---Dummy vars---
    type(Acluster),dimension(:,:),allocatable,target::HOST_Clusters
    type(Acluster),device,dimension(:,:),allocatable::DEV_Clusters
    integer::NC
    !---Local Vars---
    integer::err
    type(C_PTR)::hp_Clusters
    type(C_DEVPTR)::dp_Clusters

    !---Body---


    if(NC .GT. size(HOST_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of host clusters:",size(HOST_Clusters), &
                    "less than the copyin clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(DEV_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of device clusters:",size(DEV_Clusters), &
                    "less than the copyin clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    hp_Clusters = c_loc(HOST_Clusters)
    dp_Clusters = c_devloc(DEV_Clusters)
    err = cudaMemcpyAsync(dp_Clusters,hp_Clusters,NC*Get_MemoryConsuming_ClusterType())

    return
  end subroutine copyInClustersAsync2D

  !*****************************************************************
  subroutine copyOutClustersSync(HOST_Clusters,DEV_Clusters,NC)
    !***  PURPOSE:  to copy the Clusters From Device to Host (Sychronize)
    !     INPUT:    HOST_Clusters, the clusters array in host
    !               DEV_Clusters , the clusters array in device
    !               NC           , the number of clusters that need to copy

    !---Dummy vars---
    type(Acluster), dimension(:),allocatable,target::HOST_Clusters
    type(Acluster), device,dimension(:),allocatable::DEV_Clusters
    integer::NC
    !---Local Vars---
    integer::err
    type(C_PTR)::hp_Clusters
    type(C_DEVPTR)::dp_Clusters

    #ifdef MC_PROFILING
    call Time_Start(T_copyOutClustersSync_Start)
    #endif

    !---Body---
    if(NC .GT. size(HOST_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of host clusters:",size(HOST_Clusters), &
                    "less than the copyout clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(DEV_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of device clusters:",size(DEV_Clusters), &
                    "less than the copyout clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GE. 1) then
        ! Way 1
        !HOST_Clusters = DEV_Clusters

        ! Way 2
        hp_Clusters = c_loc(HOST_Clusters)
        dp_Clusters = c_devloc(DEV_Clusters)

        if(c_associated(hp_Clusters)) then
            err = cudaMemcpy(hp_Clusters,dp_Clusters,NC*Get_MemoryConsuming_ClusterType(),cudaMemcpyDeviceToHost)
        else
            write(*,*) "clusters copy out failed as the non-associated pointer"
        end if
    end if


    #ifdef MC_PROFILING
    call Time_Accumulate(T_copyOutClustersSync_Start,T_copyOutClustersSync)
    #endif
    return
  end subroutine copyOutClustersSync

  !*****************************************************************
  subroutine copyOutClustersSync2D(HOST_Clusters,DEV_Clusters,NC)
    !***  PURPOSE:  to copy the Clusters From Device to Host (Sychronize)
    !     INPUT:    HOST_Clusters, the clusters array in host
    !               DEV_Clusters , the clusters array in device
    !               NC           , the number of clusters that need to copy

    !---Dummy vars---
    type(Acluster), dimension(:,:),allocatable,target::HOST_Clusters
    type(Acluster), device,dimension(:,:),allocatable::DEV_Clusters
    integer::NC
    !---Local Vars---
    integer::err
    type(C_PTR)::hp_Clusters
    type(C_DEVPTR)::dp_Clusters

    #ifdef MC_PROFILING
    call Time_Start(T_copyOutClustersSync_Start)
    #endif

    !---Body---
    if(NC .GT. size(HOST_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of host clusters:",size(HOST_Clusters), &
                    "less than the copyout clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(DEV_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of device clusters:",size(DEV_Clusters), &
                    "less than the copyout clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GE. 1) then
        ! Way 1
        !HOST_Clusters = DEV_Clusters

        ! Way 2
        hp_Clusters = c_loc(HOST_Clusters)
        dp_Clusters = c_devloc(DEV_Clusters)

        if(c_associated(hp_Clusters)) then
            err = cudaMemcpy(hp_Clusters,dp_Clusters,NC*Get_MemoryConsuming_ClusterType(),cudaMemcpyDeviceToHost)
        else
            write(*,*) "clusters copy out failed as the non-associated pointer"
        end if
    end if


    #ifdef MC_PROFILING
    call Time_Accumulate(T_copyOutClustersSync_Start,T_copyOutClustersSync)
    #endif
    return
  end subroutine copyOutClustersSync2D

  !*****************************************************************
  subroutine copyOutClustersAsync(HOST_Clusters,DEV_Clusters,NC)
    !***  PURPOSE:  to copy the Clusters From Device to Host (Asyc)
    !     INPUT:    HOST_Clusters, the clusters array in host
    !               DEV_Clusters , the clusters array in device
    !               NC           , the number of clusters that need to copy

    !---Dummy vars---
    type(Acluster), dimension(:),allocatable,target::HOST_Clusters
    type(Acluster), device,dimension(:),allocatable::DEV_Clusters
    integer::NC
    !---Local Vars---
    integer::err
    type(C_PTR)::hp_Clusters
    type(C_DEVPTR)::dp_Clusters

    !---Body---
    if(NC .GT. size(HOST_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of host clusters:",size(HOST_Clusters), &
                    "less than the copyout clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(DEV_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of device clusters:",size(DEV_Clusters), &
                    "less than the copyout clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    hp_Clusters = c_loc(HOST_Clusters)
    dp_Clusters = c_devloc(DEV_Clusters)
    if(c_associated(hp_Clusters)) then
       err = cudaMemcpyAsync(hp_Clusters,dp_Clusters,NC*Get_MemoryConsuming_ClusterType(),cudaMemcpyDeviceToHost)
    else
       write(*,*) "clusters copy out failed as the non-associated pointer"
       pause
       stop
    end if

    return
  end subroutine copyOutClustersAsync

  !*****************************************************************
  subroutine copyOutClustersAsync2D(HOST_Clusters,DEV_Clusters,NC)
    !***  PURPOSE:  to copy the Clusters From Device to Host (Asyc)
    !     INPUT:    HOST_Clusters, the clusters array in host
    !               DEV_Clusters , the clusters array in device
    !               NC           , the number of clusters that need to copy

    !---Dummy vars---
    type(Acluster), dimension(:,:),allocatable,target::HOST_Clusters
    type(Acluster), device,dimension(:,:),allocatable::DEV_Clusters
    integer::NC
    !---Local Vars---
    integer::err
    type(C_PTR)::hp_Clusters
    type(C_DEVPTR)::dp_Clusters

    !---Body---
    if(NC .GT. size(HOST_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of host clusters:",size(HOST_Clusters), &
                    "less than the copyout clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(DEV_Clusters)) then
        write(*,*) "MCPSCUERROR: The size of device clusters:",size(DEV_Clusters), &
                    "less than the copyout clusters size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    hp_Clusters = c_loc(HOST_Clusters)
    dp_Clusters = c_devloc(DEV_Clusters)
    if(c_associated(hp_Clusters)) then
       err = cudaMemcpyAsync(hp_Clusters,dp_Clusters,NC*Get_MemoryConsuming_ClusterType(),cudaMemcpyDeviceToHost)
    else
       write(*,*) "clusters copy out failed as the non-associated pointer"
       pause
       stop
    end if

    return
  end subroutine copyOutClustersAsync2D

  !*****************************************************************
  subroutine copyInGrainSeedsSync(Host_Seeds,Dev_Seeds,NSeed)
    implicit none
    !---Dummy vars---
    type(GrainSeed),dimension(:),allocatable,target::Host_Seeds
    type(GrainSeed),device,dimension(:),allocatable,target::Dev_Seeds
    integer,intent(in)::NSeed
    !---Local Vars---
    integer::err
    type(C_PTR)::hp_GrainSeeds
    type(C_DEVPTR)::dp_GrainSeeds
    !---Body---

    if(NSeed .LE. 0) then
        return
    end if

    if(NSeed .GT. size(Host_Seeds)) then
        write(*,*) "MCPSCUERROR: The size of host seeds array:",size(Host_Seeds), &
                    "less than the copyin seeds size :",NSeed
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NSeed .GT. size(Dev_Seeds)) then
        write(*,*) "MCPSCUERROR: The size of device seeds array:",size(Dev_Seeds), &
                    "less than the copyin seeds size :",NSeed
        write(*,*) "The program would stop."
        pause
        stop
    end if

    hp_GrainSeeds = c_loc(Host_Seeds)
    dp_GrainSeeds = c_devloc(Dev_Seeds)

    if(c_associated(hp_GrainSeeds)) then
        err = cudaMemcpy(dp_GrainSeeds,hp_GrainSeeds,NSeed*Get_MemoryConsuming_GrainSeed(),cudaMemcpyHostToDevice)
    else
        write(*,*) "MCPSCUERROR: Grain seeds copyin failed for non-associated pointer in host."
        pause
        stop
    end if

    return
  end subroutine copyInGrainSeedsSync

  !*****************************************************************
  subroutine copyInGrainSeedsAsync(Host_Seeds,Dev_Seeds,NSeed)
    implicit none
    !---Dummy vars---
    type(GrainSeed),dimension(:),allocatable,target::Host_Seeds
    type(GrainSeed),device,dimension(:),allocatable,target::Dev_Seeds
    integer,intent(in)::NSeed
    !---Local Vars---
    integer::err
    type(C_PTR)::hp_GrainSeeds
    type(C_DEVPTR)::dp_GrainSeeds
    !---Body---

    if(NSeed .LE. 0) then
        return
    end if

    if(NSeed .GT. size(Host_Seeds)) then
        write(*,*) "MCPSCUERROR: The size of host seeds array:",size(Host_Seeds), &
                    "less than the copyin seeds size :",NSeed
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NSeed .GT. size(Dev_Seeds)) then
        write(*,*) "MCPSCUERROR: The size of device seeds array:",size(Dev_Seeds), &
                    "less than the copyin seeds size :",NSeed
        write(*,*) "The program would stop."
        pause
        stop
    end if

    hp_GrainSeeds = c_loc(Host_Seeds)
    dp_GrainSeeds = c_devloc(Dev_Seeds)

    if(c_associated(hp_GrainSeeds)) then
        err = cudaMemcpyAsync(dp_GrainSeeds,hp_GrainSeeds,NSeed*Get_MemoryConsuming_GrainSeed(),cudaMemcpyHostToDevice)
    else
        write(*,*) "MCPSCUERROR: Grain seeds copyin failed for non-associated pointer in host."
        pause
        stop
    end if

    return
  end subroutine copyInGrainSeedsAsync

  !*****************************************************************
  subroutine copyOutGrainSeedsSync(Host_Seeds,Dev_Seeds,NSeed)
    implicit none
    !---Dummy vars---
    type(GrainSeed),dimension(:),allocatable,target::Host_Seeds
    type(GrainSeed),device,dimension(:),allocatable,target::Dev_Seeds
    integer,intent(in)::NSeed
    !---Local Vars---
    integer::err
    type(C_PTR)::hp_GrainSeeds
    type(C_DEVPTR)::dp_GrainSeeds
    !---Body---

    if(NSeed .LE. 0) then
        return
    end if

    if(NSeed .GT. size(Host_Seeds)) then
        write(*,*) "MCPSCUERROR: The size of host seeds array:",size(Host_Seeds), &
                    "less than the copyout seeds size :",NSeed
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NSeed .GT. size(Dev_Seeds)) then
        write(*,*) "MCPSCUERROR: The size of device seeds array:",size(Host_Seeds), &
                    "less than the copyout seeds size :",NSeed
        write(*,*) "The program would stop."
        pause
        stop
    end if


    hp_GrainSeeds = c_loc(Host_Seeds)
    dp_GrainSeeds = c_devloc(Dev_Seeds)

    if(c_associated(hp_GrainSeeds)) then
        err = cudaMemcpy(hp_GrainSeeds,dp_GrainSeeds,NSeed*Get_MemoryConsuming_GrainSeed(),cudaMemcpyDeviceToHost)
    else
        write(*,*) "MCPSCUERROR: Grain seeds copyout failed for non-associated pointer in host."
        pause
        stop
    end if

    return
  end subroutine copyOutGrainSeedsSync


  !*****************************************************************
  subroutine copyOutGrainSeedsAsync(Host_Seeds,Dev_Seeds,NSeed)
    implicit none
    !---Dummy vars---
    type(GrainSeed),dimension(:),allocatable,target::Host_Seeds
    type(GrainSeed),device,dimension(:),allocatable,target::Dev_Seeds
    integer,intent(in)::NSeed
    !---Local Vars---
    integer::err
    type(C_PTR)::hp_GrainSeeds
    type(C_DEVPTR)::dp_GrainSeeds
    !---Body---

    if(NSeed .LE. 0) then
        return
    end if

    if(NSeed .GT. size(Host_Seeds)) then
        write(*,*) "MCPSCUERROR: The size of host seeds array:",size(Host_Seeds), &
                    "less than the copyout seeds size :",NSeed
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NSeed .GT. size(Dev_Seeds)) then
        write(*,*) "MCPSCUERROR: The size of device seeds array:",size(Host_Seeds), &
                    "less than the copyout seeds size :",NSeed
        write(*,*) "The program would stop."
        pause
        stop
    end if


    hp_GrainSeeds = c_loc(Host_Seeds)
    dp_GrainSeeds = c_devloc(Dev_Seeds)

    if(c_associated(hp_GrainSeeds)) then
        err = cudaMemcpyAsync(hp_GrainSeeds,dp_GrainSeeds,NSeed*Get_MemoryConsuming_GrainSeed(),cudaMemcpyDeviceToHost)
    else
        write(*,*) "MCPSCUERROR: Grain seeds copyout failed for non-associated pointer in host."
        pause
        stop
    end if

    return
  end subroutine copyOutGrainSeedsAsync

  !******************************************
  subroutine copyOutOneDimSync(Host_Array,Dev_Array,NC)
    implicit none
    !---Dummy Vars---
    integer ,dimension(:),allocatable::Host_Array
    integer ,device, dimension(:),allocatable::Dev_Array
    integer,value::NC
    !---Local Vars---
    integer::err

    #ifdef MC_PROFILING
    call Time_Start(T_copyOutActiveIndexSync_Start)
    #endif
    !---Body----
    if(NC .GT. size(Host_Array)) then
        write(*,*) "MCPSCUERROR: The size of host array:",size(Host_Array), &
                    " is less than the copyout  size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(Dev_Array)) then
        write(*,*) "MCPSCUERROR: The size of device array:",size(Dev_Array), &
                    "less than the copyout size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    !Host_Array = Dev_Array

    err = cudaMemcpy(Host_Array,Dev_Array,NC,cudaMemcpyDeviceToHost)

    #ifdef MC_PROFILING
    call Time_Accumulate(T_copyOutActiveIndexSync_Start,T_copyOutActiveIndexSync)
    #endif
    return
  end subroutine copyOutOneDimSync

  !******************************************
  subroutine copyOutOnDimAsync(Host_Array,Dev_Array,NC)
    implicit none
    !---Dummy Vars---
    integer,value::NC
    integer ,dimension(:),allocatable::Host_Array
    integer ,device, dimension(:),allocatable::Dev_Array
    !---Local Vars---
    integer::err
    !---Body----

    if(NC .GT. size(Host_Array)) then
        write(*,*) "MCPSCUERROR: The size of host  array:",size(Host_Array), &
                    " is less than the copyout  size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(Dev_Array)) then
        write(*,*) "MCPSCUERROR: The size of device  array:",size(Dev_Array), &
                    "less than the copyout  size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    err = cudaMemcpyAsync(Host_Array,Dev_Array,NC,cudaMemcpyDeviceToHost)

    return
  end subroutine copyOutOnDimAsync

  !******************************************
  subroutine copyInOneDimSync(Host_Array,Dev_Array,NC)
    implicit none
    !---Dummy Vars---
    integer ,dimension(:),allocatable::Host_Array
    integer ,device, dimension(:),allocatable::Dev_Array
    integer,value::NC
    !---Local Vars---
    integer::err
    !---Body----
    if(NC .GT. size(Host_Array)) then
        write(*,*) "MCPSCUERROR: The size of host array:",size(Host_Array), &
                    " is less than the copyin size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(Dev_Array)) then
        write(*,*) "MCPSCUERROR: The size of device array:",size(Dev_Array), &
                    "less than the copyin size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    err = cudaMemcpy(Dev_Array,Host_Array,NC,cudaMemcpyHostToDevice)

    return
  end subroutine copyInOneDimSync

  !******************************************
  subroutine copyInOneDimAsync(Host_Array,Dev_Array,NC)
    implicit none
    !---Dummy Vars---
    integer,value::NC
    integer ,dimension(:),allocatable::Host_Array
    integer ,device, dimension(:),allocatable::Dev_Array
    !---Local Vars---
    integer::err
    !---Body----
    if(NC .GT. size(Host_Array)) then
        write(*,*) "MCPSCUERROR: The size of hostArray:",size(Host_Array), &
                    " is less than the copyin size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(Dev_Array)) then
        write(*,*) "MCPSCUERROR: The size of device array:",size(Dev_Array), &
                    "less than the copyin size :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    err = cudaMemcpyAsync(Dev_Array,Host_Array,NC,cudaMemcpyHostToDevice)

    return
  end subroutine copyInOneDimAsync

  !************************************************************************************
  subroutine copyNeighborListFromGPUToCPU(NC,DEV_INDI,DEV_KVOIS,HOST_LIST)
    !*** PURPOSE: to copy the Neighbor-List From device(GPU) to host(CPU)
    !    INPUT:  NC       , the number of Clusters
    !            DEV_INDI , the array of neighbor-list in device
    !            DEV_KVOIS, the array of neighbor number
    !            HOST_LIST, the neighbor-list in host
    !    OUTPUT:
    implicit none
    !---Dummy Vars---
    integer::NC
    integer, device, dimension(:,:), allocatable::DEV_INDI
    integer, device, dimension(:), allocatable::DEV_KVOIS
    type(NEIGHBOR_LIST)::HOST_LIST
    !---Local Vars---
    integer::MAXNN

    #ifdef MC_PROFILING
    call Time_Start(T_copyNeighborListFromGPUToCPU_Start)
    #endif
    !---Body---

    if(NC .GT. size(HOST_LIST%m_INDI,1)) then
        write(*,*) "MCPSCUERROR: The rows number of host INDI:",size(HOST_LIST%m_INDI,1), &
                    "less than the copyout rows number :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if


    if(NC .GT. size(HOST_LIST%m_KVOIS)) then
        write(*,*) "MCPSCUERROR: The rows number of host KVOIS:",size(HOST_LIST%m_KVOIS), &
                    "less than the copyout rows number :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(DEV_INDI,1)) then
        write(*,*) "MCPSCUERROR: The rows number of device INDI:",size(DEV_INDI,1), &
                    "less than the copyout rows number :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(DEV_KVOIS)) then
        write(*,*) "MCPSCUERROR: The rows number of device KVOIS:",size(DEV_KVOIS), &
                    "less than the copyout rows number :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    HOST_LIST%m_KVOIS = DEV_KVOIS
    HOST_LIST%m_INDI = DEV_INDI


    #ifdef MC_PROFILING
    call Time_Accumulate(T_copyNeighborListFromGPUToCPU_Start,T_copyNeighborListFromGPUToCPU)
    #endif
    return
  end subroutine copyNeighborListFromGPUToCPU


  !************************************************************************************
  subroutine copyNeighborListFromCPUToGPU(NC,DEV_INDI,DEV_KVOIS,HOST_LIST)
    !*** PURPOSE: to copy the Neighbor-List From host(CPU) to device(GPU)
    !    INPUT:  NC       , the number of Clusters
    !            DEV_INDI , the array of neighbor-list in device
    !            DEV_KVOIS, the array of neighbor number
    !            HOST_LIST, the neighbor-list in host
    !    OUTPUT:
    implicit none
    !---Dummy Vars---
    integer::NC
    integer, device, dimension(:,:), allocatable::DEV_INDI
    integer, device, dimension(:), allocatable::DEV_KVOIS
    type(NEIGHBOR_LIST)::HOST_LIST
    !---Local Vars---
    integer::MAXNN

    #ifdef MC_PROFILING
    call Time_Start(T_copyNeighborListFromGPUToCPU_Start)
    #endif
    !---Body---

    if(NC .GT. size(HOST_LIST%m_INDI,1)) then
        write(*,*) "MCPSCUERROR: The rows number of host INDI:",size(HOST_LIST%m_INDI,1), &
                    "less than the copyout rows number :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if


    if(NC .GT. size(HOST_LIST%m_KVOIS)) then
        write(*,*) "MCPSCUERROR: The rows number of host KVOIS:",size(HOST_LIST%m_KVOIS), &
                    "less than the copyout rows number :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(DEV_INDI,1)) then
        write(*,*) "MCPSCUERROR: The rows number of device INDI:",size(DEV_INDI,1), &
                    "less than the copyout rows number :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    if(NC .GT. size(DEV_KVOIS)) then
        write(*,*) "MCPSCUERROR: The rows number of device KVOIS:",size(DEV_KVOIS), &
                    "less than the copyout rows number :",NC
        write(*,*) "The program would stop."
        pause
        stop
    end if

    DEV_KVOIS = HOST_LIST%m_KVOIS
    DEV_INDI = HOST_LIST%m_INDI

    #ifdef MC_PROFILING
    call Time_Accumulate(T_copyNeighborListFromGPUToCPU_Start,T_copyNeighborListFromGPUToCPU)
    #endif
    return
  end subroutine copyNeighborListFromCPUToGPU

  !******************************************
  integer function getBlockFilledSize(TNC)
    !***Purpose: to get the block filled array size
    !    TNC   : the original-size
    implicit none
    !---Dummy Vars---
    integer, intent(in)::TNC
    !---Local Vars---
    integer::NB, NBX, NBY


    #ifdef MC_PROFILING
    call Time_Start(T_getBlockFilledSize_Start)
    #endif
    !---Body---
    NB  = (TNC-1)/p_BLOCKSIZE+1
    NBX = min(NB, p_BLOCKDIMX)
    NBY = (NB-1)/NBX+1
    NB  = NBX*NBY

    getBlockFilledSize = NB*p_BLOCKSIZE

    #ifdef MC_PROFILING
    call Time_Accumulate(T_getBlockFilledSize_Start,T_getBlockFilledSize)
    #endif
    return
  end function getBlockFilledSize


  !*********************************************
  subroutine InitialDevRandRecordArray(Dev_Array,NSize,Seed,offset)
    !---Dummy Vars---
    type(curandStateXORWOW),device,dimension(:),allocatable::Dev_Array
    integer,intent(in)::NSize
    integer,intent(in)::Seed
    integer,optional::offset
    !---Local Vars---
    integer::NB
    integer::NBX
    integer::NBY
    integer::BX
    integer::BY
    type(dim3)::threads
    type(dim3)::blocks
    !---Body---
    if(NSize .GT. size(Dev_Array)) then
        write(*,*) "MCPSCUERROR: the device random number generator array size is : ",size(Dev_Array)
        write(*,*) "However, the size you specialed is : ",NSize
        pause
        stop
    end if

    NB = (NSize - 1)/p_BLOCKSIZE + 1
    NBX = p_BLOCKDIMX
    NBY = (NB - 1)/p_BLOCKDIMX + 1
    BX = p_BLOCKSIZE
    BY = 1

    threads = dim3(BX,BY,1)
    blocks = dim3(NBX,NBY,1)

    if(present(offset)) then
        call Kernel_InitialRandRecord<<<blocks,threads>>>(Dev_Array,NSize,Seed,offset)
    else
        call Kernel_InitialRandRecord<<<blocks,threads>>>(Dev_Array,NSize,Seed,0)
    end if

    return
  end subroutine

  !*********************************************
  attributes(global) subroutine Kernel_InitialRandRecord(Dev_Array,NSize,Seed,offset)
    use curand_device
    implicit none
    !---Dummy Vars---
    type(curandStateXORWOW),dimension(:),device::Dev_Array
    integer,value::NSize
    integer,value::Seed
    integer,value::offset
    !---Local Vars---
    integer::bid
    integer::tid
    integer::IC
    integer::Seq
    !---Body---
    bid = (blockidx%y - 1)*griddim%x + blockidx%x
    tid = (threadidx%y - 1)*blockdim%x + threadidx%x
    IC = (bid - 1)*p_BLOCKSIZE + tid

    Seq = IC

    if(IC .LE. NSize) then
        call curandInitXORWOW(Seed,Seq,offset,Dev_Array(IC))
    end if

    return
  end subroutine Kernel_InitialRandRecord



  !!***********************************************
!  __device__ inline void Comparetor_toApply(double &KeyA, double &KeyB, int &ValueA, int &ValueB,int dir) {
!	double temp;
!	int tempValue;
!	// dir 0 for decreasing , dir 1 for increasing
!
!	if ((KeyA > KeyB) == dir) {
!		temp = KeyA;
!		KeyA = KeyB;
!		KeyB = temp;
!		tempValue = ValueA;
!		ValueA = ValueB;
!		ValueB = tempValue;
!	}
!}

  attributes(device) subroutine Comparetor_toApply_Shared(KeyA,KeyB,ValueA,ValueB,dir)
    implicit none
    !---Dummy Vars---
    real(kind=KINDDF)::KeyA
    real(kind=KINDDF)::KeyB
    integer::ValueA
    integer::ValueB
    integer::dir
    !--Local Vars---
    real(kind=KINDDF)::tempKey
    integer::tempValue
    !---Body---
    if((KeyA .GT. KeyB) .eq. (dir .eq. p_Sort_Ascending) ) then
		tempKey = KeyA
		KeyA = KeyB
		KeyB = tempKey
		tempValue = ValueA
		ValueA = ValueB
		ValueB = tempValue
    end if

    return
  end subroutine Comparetor_toApply_Shared


  attributes(device) subroutine Comparetor_toApply_Global(posA,posB,KeyArray,ValueArray,dir)
    implicit none
    !---Dummy Vars---
    integer::posA
    integer::posB
    type(ACluster),device::KeyArray(:)
    integer,device::ValueArray(:)
    integer::dir
    !--Local Vars---
    real(kind=KINDDF)::KeyA
    real(kind=KINDDF)::KeyB
    integer::ValueA
    integer::ValueB
    integer::tempValue
    !---Body---
    ValueA = ValueArray(posA)
    ValueB = ValueArray(posB)
    KeyA = KeyArray(ValueA)%m_POS(1)
    KeyB = KeyArray(ValueB)%m_POS(1)

    if((KeyA .GT. KeyB) .eq. (dir .eq. p_Sort_Ascending) ) then
		ValueArray(posA) = ValueB
        ValueArray(posB) = ValueA
    end if

    return
  end subroutine Comparetor_toApply_Global

  !*************************************************************************
!/*Used For Array Size less than BLOCKSIZE And is not of power 2*/
!__global__ void Kernel_Shared_ArbitraryBitonicSort_toApply(double* Dev_TestArray,int* SortedIndex, int** IDStartEnd_ForSort, int dir, double padNum) {
!	int tid = threadIdx.y*blockDim.x + threadIdx.x;
!	int bid = blockIdx.y*gridDim.x + blockIdx.x;
!	int tempDir;
!	int pos;
!	int LastPowerTwo;
!	int ICStart;
!	int ICEnd;
!	int IDRelative;
!	int SegmentSize;
!	double __shared__ Share_TestArray[BLOCKSIZE_TOAPPLY];
!	int __shared__ Share_SortedIndex[BLOCKSIZE_TOAPPLY];
!
!	ICStart = IDStartEnd_ForSort[bid][0];
!	ICEnd = IDStartEnd_ForSort[bid][1];
!	IDRelative = ICStart + tid;
!
!	Share_TestArray[tid] = padNum;
!	if (IDRelative <= ICEnd) {
!		Share_TestArray[tid] = Dev_TestArray[IDRelative];
!		Share_SortedIndex[tid] = SortedIndex[IDRelative];
!	}
!
!	Share_TestArray[tid + BLOCKSIZE_TOAPPLY / 2] = padNum;
!	if ((IDRelative + BLOCKSIZE_TOAPPLY / 2) <= ICEnd) {
!		Share_TestArray[tid + BLOCKSIZE_TOAPPLY / 2] = Dev_TestArray[IDRelative + BLOCKSIZE_TOAPPLY / 2];
!		Share_SortedIndex[tid + BLOCKSIZE_TOAPPLY / 2] = SortedIndex[IDRelative + BLOCKSIZE_TOAPPLY / 2];
!	}
!
!	LastPowerTwo = 1;
!
!	SegmentSize = ICEnd - ICStart + 1;
!
!	for (int i = 2; i < SegmentSize; i <<= 1) {
!
!		LastPowerTwo = i;
!
!		tempDir = dir ^ ((tid & (i / 2)) != 0);
!
!
!		for (int stride = i / 2; stride > 0; stride >>= 1) {
!
!			__syncthreads();
!
!			pos = 2 * tid - (tid & (stride - 1));
!
!			Comparetor_toApply(Share_TestArray[pos], Share_TestArray[pos + stride], Share_SortedIndex[pos], Share_SortedIndex[pos + stride], tempDir);
!
!		}
!	}
!
!	for (int stride = LastPowerTwo; stride > 0; stride >>= 1) {
!		__syncthreads();
!
!		pos = 2 * tid - (tid & (stride - 1));
!
!		Comparetor_toApply(Share_TestArray[pos], Share_TestArray[pos + stride],Share_SortedIndex[pos], Share_SortedIndex[pos + stride], dir);
!
!	}
!
!	__syncthreads();
!
!	if (IDRelative <= ICEnd) {
!		Dev_TestArray[IDRelative] = Share_TestArray[tid];
!		SortedIndex[IDRelative] = Share_SortedIndex[tid];
!	}
!	if ((IDRelative + BLOCKSIZE_TOAPPLY / 2) <= ICEnd) {
!		Dev_TestArray[IDRelative + BLOCKSIZE_TOAPPLY / 2] = Share_TestArray[tid + BLOCKSIZE_TOAPPLY / 2];
!		SortedIndex[IDRelative + BLOCKSIZE_TOAPPLY / 2] = Share_SortedIndex[tid + BLOCKSIZE_TOAPPLY / 2];
!	}
!}

  !/*Used For Array Size less than BLOCKSIZE And is not of power 2*/
  attributes(global) subroutine Kernel_Shared_ArbitraryBitonicSort_toApply(KeyArray,ValueArray,IDStartEnd_ForSort,dir,padNum)
    implicit none
    !---Dummy Vars---
    type(ACluster),device::KeyArray(:)
    integer,device::ValueArray(:)
    integer,device::IDStartEnd_ForSort(:,:)
    integer,value::dir
    real(kind=KINDDF),value::padNum
    !---Local Vars---
    integer::tid
    integer::bid
    integer::tempDir
    integer::pos
    integer::LastPowerTwo
    integer::ICStart
    integer::ICEnd
    integer::IDRelative
    integer::SegmentSize
    real(kind=KINDDF),shared,dimension(p_BLOCKSIZE_BITONIC)::Share_KeysArray
    integer,shared,dimension(p_BLOCKSIZE_BITONIC)::Share_ValuesArray
    integer::I
    integer::stride
    integer::LeftHalf
    !---Body---
    tid = (threadidx%y - 1)*blockdim%x + threadidx%x
    bid = (blockidx%y -1)*griddim%x + blockidx%x

    ICStart = IDStartEnd_ForSort(bid,1)
	ICEnd = IDStartEnd_ForSort(bid,2)
	IDRelative = ICStart + tid - 1

	Share_KeysArray(tid) = padNum
	if (IDRelative .LE. ICEnd) then
		Share_KeysArray(tid) = KeyArray(IDRelative)%m_POS(1)
		Share_ValuesArray(tid) = IDRelative
	end if

	Share_KeysArray(tid + p_BLOCKSIZE_BITONIC / 2) = padNum
	if ((IDRelative + p_BLOCKSIZE_BITONIC / 2) .LE. ICEnd) then
		Share_KeysArray(tid + p_BLOCKSIZE_BITONIC / 2) = KeyArray(IDRelative + p_BLOCKSIZE_BITONIC / 2)%m_POS(1)
		Share_ValuesArray(tid + p_BLOCKSIZE_BITONIC / 2) = IDRelative + p_BLOCKSIZE_BITONIC/2
	end if

	LastPowerTwo = 1

	SegmentSize = ICEnd - ICStart + 1

    I = 2
    DO While(I .LT. SegmentSize)

        LastPowerTwo = I

        LeftHalf = (IAND(tid-1,I/2) .ne. 0)

        LeftHalf = LeftHalf*LeftHalf  ! in PGI compiler the .true. is -1 in integer form,false is 0 in integer form

        tempDir = IEOR(dir,LeftHalf)

        stride = I/2
        DO while(stride .GT. 0)
            call syncthreads()

            pos = 2 * (tid -1) - IAND(tid-1,stride - 1) + 1

            call Comparetor_toApply_Shared(Share_KeysArray(pos), Share_KeysArray(pos + stride), Share_ValuesArray(pos), Share_ValuesArray(pos + stride), tempDir)

            stride = ISHFT(stride,-1)

        END DO

        I = ISHFT(I,1)
    END DO

    stride = LastPowerTwo

    DO while(stride .GT. 0)
        call syncthreads()

        pos = 2 * (tid -1) - IAND(tid-1,stride - 1) + 1

        call Comparetor_toApply_Shared(Share_KeysArray(pos), Share_KeysArray(pos + stride), Share_ValuesArray(pos), Share_ValuesArray(pos + stride), dir)

        stride = ISHFT(stride,-1)
    END DO

	call syncthreads()

	if (IDRelative .LE. ICEnd) then
!		KeyArray(IDRelative) = Share_KeysArray(tid)
		ValueArray(IDRelative) = Share_ValuesArray(tid)
	end if

	if ((IDRelative + p_BLOCKSIZE_BITONIC / 2) .LE. ICEnd) then
!		KeyArray(IDRelative + p_BLOCKSIZE_BITONIC / 2) = Share_KeysArray(tid + p_BLOCKSIZE_BITONIC / 2)
		ValueArray(IDRelative + p_BLOCKSIZE_BITONIC / 2) = Share_ValuesArray(tid + p_BLOCKSIZE_BITONIC / 2)
	end if

    return
  end subroutine Kernel_Shared_ArbitraryBitonicSort_toApply



  !__global__ void Kernel_GlobalMerge_Pre_toApply(int BlockNumEachBox,int Size, int SegmentsStride, int** IDStartEnd_ForSort, double* Dev_TestArray, int dir, int *OEFlags) {
!	int tid = threadIdx.y*blockDim.x + threadIdx.x;
!	int bid = blockIdx.y*gridDim.x + blockIdx.x;
!	int cid = bid * blockDim.x * blockDim.y + tid;
!	int tempDir;
!	int IDSegRelative;
!	int IBox;
!	int cid0;
!	int IDSegStartRelative;
!	int IDLevel;
!	int IDSegStart;
!	int IDSegEnd;
!	int IDSegMap;
!	int ICLevelStart;
!	int ICLevelRightHalfStart;
!	int ICLevelRightHalfEnd;
!	int ICLevelEnd;
!	int FlagsShift;
!
!	IBox = cid / BlockNumEachBox;
!	cid0 = IBox * BlockNumEachBox;
!	IDSegRelative = cid - cid0;
!
!	IDLevel = IDSegRelative / SegmentsStride;
!	IDSegStartRelative = IDLevel * 2 * SegmentsStride;
!	IDSegStart = 2* cid0 + IDSegStartRelative;
!	IDSegEnd = 2* cid0 + (IDLevel + 1) * 2 * SegmentsStride - 1;
!	IDSegMap = IDSegStart + IDSegRelative % SegmentsStride;
!
!
!	tempDir = dir ^ ((IDSegStartRelative / Size) & 1);
!
!	ICLevelStart = *(*(IDStartEnd_ForSort + IDSegStart) + 0);
!	ICLevelEnd = *(*(IDStartEnd_ForSort + IDSegEnd) + 1);
!
!	ICLevelRightHalfStart = *(*(IDStartEnd_ForSort + IDSegStart + SegmentsStride) + 0);
!	ICLevelRightHalfEnd = ICLevelEnd;
!
!	FlagsShift = tempDir ^ (Dev_TestArray[ICLevelRightHalfEnd] >= Dev_TestArray[ICLevelRightHalfStart]);
!
!	OEFlags[IDSegMap] = ((ICLevelEnd - ICLevelStart + 1) % 2 != 0)&FlagsShift;
!}

  attributes(global) subroutine Kernel_GlobalMerge_Pre_toApply(BlockNumEachBox,TheSize, SegmentsStride, IDStartEnd_ForSort, KeyArray,ValueArray, dir, OEFlags)
    implicit none
    !---Dummy Vars----
    integer,value::BlockNumEachBox
    integer,value::TheSize
    integer,value::SegmentsStride
    integer,device::IDStartEnd_ForSort(:,:)
    type(ACluster),device::KeyArray(:)
    integer,device::ValueArray(:)
    integer,value::dir
    integer,device::OEFlags(:)
    !---Local Vars---
	integer::tid
	integer::bid
	integer::cid
	integer::tempDir
	integer::IDSegRelative
	integer::IBox
	integer::cid0
	integer::IDSegStartRelative
	integer::IDLevel
	integer::IDSegStart
	integer::IDSegEnd
	integer::IDSegMap
	integer::ICLevelStart
	integer::ICLevelRightHalfStart
	integer::ICLevelRightHalfEnd
	integer::ICLevelEnd
	integer::FlagsShift
	integer::LogicalToInt
    !---Body---
    tid = (threadidx%y - 1)*blockdim%x + threadidx%x
    bid = (blockidx%y -1)*griddim%x + blockidx%x
    cid = (bid -1)*blockdim%x*blockdim%y + tid

	IBox = (cid -1)/BlockNumEachBox + 1
	cid0 = (IBox-1)*BlockNumEachBox + 1
	IDSegRelative = cid - cid0

	IDLevel = IDSegRelative/SegmentsStride
	IDSegStartRelative = IDLevel * 2 * SegmentsStride
	IDSegStart = 2* (cid0 - 1) + IDSegStartRelative + 1
	IDSegEnd = 2* (cid0 -1) + (IDLevel + 1) * 2 * SegmentsStride
	IDSegMap = IDSegStart + mod(IDSegRelative,SegmentsStride)

    tempDir = IEOR(dir,IAND(IDSegStartRelative/TheSize,1))

	ICLevelStart = IDStartEnd_ForSort(IDSegStart,1)
	ICLevelEnd = IDStartEnd_ForSort(IDSegEnd,2)

	ICLevelRightHalfStart = IDStartEnd_ForSort(IDSegStart + SegmentsStride,1)
	ICLevelRightHalfEnd = ICLevelEnd

    if(ICLevelRightHalfStart.GT. 0 .AND. ICLevelRightHalfEnd .GT. 0) then
        LogicalToInt = (KeyArray(ValueArray(ICLevelRightHalfEnd))%m_POS(1) .GE. KeyArray(ValueArray(ICLevelRightHalfStart))%m_POS(1))

        LogicalToInt = LogicalToInt*LogicalToInt   ! in PGI compiler the .true. is -1 in integer form,false is 0 in integer form

        FlagsShift = IEOR(tempDir,LogicalToInt)

        LogicalToInt = (mod(ICLevelEnd - ICLevelStart + 1,2) .ne. 0)

        LogicalToInt = LogicalToInt*LogicalToInt ! in PGI compiler the .true. is -1 in integer form,false is 0 in integer form

        OEFlags(IDSegMap) = IAND(LogicalToInt,FlagsShift)
    END if

    return
  end subroutine Kernel_GlobalMerge_Pre_toApply

!__global__ void Kernel_GlobalMerge_toApply(int BlockNumEachBox,int Size, int SegmentsStride, int** IDStartEnd_ForSort, double* Dev_TestArray, int* SortedIndex, int dir, int *OEFlags) {
!	int tid = threadIdx.y*blockDim.x + threadIdx.x;
!	int bid = blockIdx.y*gridDim.x + blockIdx.x;
!	int cid = bid * blockDim.x * blockDim.y + tid;
!	int IBox;
!	int bid0;
!	int tempDir;
!	int pos;
!	int IDLevel;
!	int IDSegStart;
!	int IDSegEnd;
!	int IDSegMap;
!	int ICSegStart;
!	int ICSegEnd;
!	int ICLevelStart;
!	int ICLevelEnd;
!	int Stride;
!	int IDSegRelative;
!	int IDSegStartRelative;
!
!	IBox = bid / BlockNumEachBox;
!	bid0 = IBox * BlockNumEachBox;
!	IDSegRelative = bid - bid0;
!	IDLevel = IDSegRelative / SegmentsStride;
!	IDSegStartRelative = IDLevel * 2 * SegmentsStride;
!	IDSegStart = 2*bid0 + IDSegStartRelative;
!	IDSegEnd = 2*bid0 + (IDLevel + 1) * 2 * SegmentsStride - 1;
!	IDSegMap = IDSegStart + IDSegRelative % SegmentsStride;
!
!	tempDir = dir ^ ((IDSegStartRelative / Size) & 1);
!
!	ICSegStart = *(*(IDStartEnd_ForSort + IDSegMap) + 0);
!	ICSegEnd = *(*(IDStartEnd_ForSort + IDSegMap) + 1);
!
!	pos = ICSegStart + tid;
!
!	ICLevelStart = *(*(IDStartEnd_ForSort + IDSegStart) + 0);
!	ICLevelEnd = *(*(IDStartEnd_ForSort + IDSegEnd) + 1);
!
!	Stride = (ICLevelEnd - ICLevelStart + 1) / 2 + OEFlags[IDSegMap];
!
!	if (pos <= ICSegEnd && (pos + Stride) <= ICLevelEnd) {
!		Comparetor_toApply(Dev_TestArray[pos], Dev_TestArray[pos + Stride], SortedIndex[pos], SortedIndex[pos + Stride], tempDir);
!	}
!}


  attributes(global) subroutine Kernel_GlobalMerge_toApply(BlockNumEachBox,TheSize, SegmentsStride, IDStartEnd_ForSort, KeyArray,ValueArray, dir, OEFlags)
    implicit none
    !---Dummy Vars----
    integer,value::BlockNumEachBox
    integer,value::TheSize
    integer,value::SegmentsStride
    integer,device::IDStartEnd_ForSort(:,:)
    type(ACluster),device::KeyArray(:)
    integer,device::ValueArray(:)
    integer,value::dir
    integer,device::OEFlags(:)
    !---Local Vars---
	integer::tid
	integer::bid
	integer::tempDir
	integer::IDSegRelative
	integer::IBox
	integer::bid0
	integer::IDSegStartRelative
	integer::IDLevel
	integer::IDSegStart
	integer::IDSegEnd
	integer::IDSegMap
    integer::ICSegStart
	integer::ICSegEnd
	integer::ICLevelStart
	integer::ICLevelEnd
	integer::FlagsShift
	integer::LogicalToInt
	integer::pos
	integer::Stride
    !---Body---
    tid = (threadidx%y - 1)*blockdim%x + threadidx%x
    bid = (blockidx%y -1)*griddim%x + blockidx%x

	IBox = (bid -1)/BlockNumEachBox + 1
	bid0 = (IBox-1)*BlockNumEachBox + 1
	IDSegRelative = bid - bid0
    IDLevel = IDSegRelative/SegmentsStride
	IDSegStartRelative = IDLevel * 2 * SegmentsStride
	IDSegStart = 2* (bid0 - 1) + IDSegStartRelative + 1
	IDSegEnd = 2* (bid0 -1) + (IDLevel + 1) * 2 * SegmentsStride
	IDSegMap = IDSegStart + mod(IDSegRelative,SegmentsStride)

	tempDir = IEOR(dir,IAND(IDSegStartRelative/TheSize,1))

	ICSegStart = IDStartEnd_ForSort(IDSegMap,1)
	ICSegEnd = IDStartEnd_ForSort(IDSegMap,2)

    if(ICSegEnd .GT. 0) then

        pos = ICSegStart + tid - 1

        ICLevelStart = IDStartEnd_ForSort(IDSegStart,1)
        ICLevelEnd = IDStartEnd_ForSort(IDSegEnd,2)

        Stride = (ICLevelEnd - ICLevelStart + 1) / 2 + OEFlags(IDSegMap)

        if (pos .LE. ICSegEnd .AND. (pos + Stride) .LE. ICLevelEnd) then

            call Comparetor_toApply_Global(pos, pos + Stride,KeyArray, ValueArray, tempDir)

        end if
    end if
    return
  end subroutine Kernel_GlobalMerge_toApply

!/*Used For Array Size less than BLOCKSIZE And is not of power 2*/
!__global__ void Kernel_Shared_Merge_toApply(int BlockNumEachBox_Share,double* Dev_TestArray,int* SortedIndex, int** IDStartEnd_ForSort, int dir, double padNum, int Size) {
!	int tid = threadIdx.y*blockDim.x + threadIdx.x;
!	int bid = blockIdx.y*gridDim.x + blockIdx.x;
!	int tempDir;
!	int pos;
!	int LastPowerTwo;
!	int SegmentSize;
!	int ICStart;
!	int ICEnd;
!	int IDRelative;
!	double tempPadNum;
!	int IBox;
!	int bid0;
!	int IDSegRelative;
!
!	double __shared__ Share_TestArray[BLOCKSIZE_TOAPPLY];
!	int __shared__ Share_SortedIndex[BLOCKSIZE_TOAPPLY];
!
!	IBox = bid / BlockNumEachBox_Share;
!	bid0 = IBox * BlockNumEachBox_Share;
!	IDSegRelative = bid - bid0;
!
!	ICStart = IDStartEnd_ForSort[bid][0];
!	ICEnd = IDStartEnd_ForSort[bid][1];
!	IDRelative = ICStart + tid;
!	tempPadNum = (1 - 2 * ((IDSegRelative / Size) % 2))*padNum;
!
!	if (ICEnd > 0) {
!
!		Share_TestArray[tid] = tempPadNum;
!		if (IDRelative <= ICEnd) {
!			Share_TestArray[tid] = Dev_TestArray[IDRelative];
!			Share_SortedIndex[tid] = SortedIndex[IDRelative];
!		}
!
!		Share_TestArray[tid + BLOCKSIZE_TOAPPLY / 2] = tempPadNum;
!		if ((IDRelative + BLOCKSIZE_TOAPPLY / 2) <= ICEnd) {
!			Share_TestArray[tid + BLOCKSIZE_TOAPPLY / 2] = Dev_TestArray[IDRelative + BLOCKSIZE_TOAPPLY / 2];
!			Share_SortedIndex[tid + BLOCKSIZE_TOAPPLY / 2] = SortedIndex[IDRelative + BLOCKSIZE_TOAPPLY / 2];
!		}
!
!		LastPowerTwo = 1;
!
!		SegmentSize = ICEnd - ICStart + 1;
!
!		for (int i = 2; i < SegmentSize; i <<= 1) {
!
!			LastPowerTwo = i;
!
!			tempDir = ((IDSegRelative / Size) % 2) ^ (dir ^ ((tid & (i / 2)) != 0));
!
!			for (int stride = i / 2; stride > 0; stride >>= 1) {
!
!				__syncthreads();
!
!				pos = 2 * tid - (tid & (stride - 1));
!
!				Comparetor_toApply(Share_TestArray[pos], Share_TestArray[pos + stride], Share_SortedIndex[pos], Share_SortedIndex[pos + stride], tempDir);
!
!			}
!		}
!
!		tempDir = ((IDSegRelative / Size) % 2) ^ dir;
!
!		for (int stride = LastPowerTwo; stride > 0; stride >>= 1) {
!			__syncthreads();
!
!			pos = 2 * tid - (tid & (stride - 1));
!
!			Comparetor_toApply(Share_TestArray[pos], Share_TestArray[pos + stride], Share_SortedIndex[pos], Share_SortedIndex[pos + stride], tempDir);
!		}
!
!		__syncthreads();
!
!		if (IDRelative <= ICEnd) {
!			Dev_TestArray[IDRelative] = Share_TestArray[tid];
!			SortedIndex[IDRelative] = Share_SortedIndex[tid];
!		}
!		if ((IDRelative + BLOCKSIZE_TOAPPLY / 2) <= ICEnd) {
!			Dev_TestArray[IDRelative + BLOCKSIZE_TOAPPLY / 2] = Share_TestArray[tid + BLOCKSIZE_TOAPPLY / 2];
!			SortedIndex[IDRelative + BLOCKSIZE_TOAPPLY / 2] = Share_SortedIndex[tid + BLOCKSIZE_TOAPPLY / 2];
!		}
!
!	}
!}

  !***********Used For Array Size less than BLOCKSIZE And is not of power 2******************
  attributes(global) subroutine Kernel_Shared_Merge_toApply(BlockNumEachBox_Share,KeyArray,ValueArray,IDStartEnd_ForSort,dir,padNum,TheSize)
    !---Dummy Vars----
    integer,value::BlockNumEachBox_Share
    type(ACluster),device::KeyArray(:)
    integer,device::ValueArray(:)
    integer,device::IDStartEnd_ForSort(:,:)
    integer,value::dir
    real(kind=KINDDF),value::padNum
    integer,value::TheSize
    !---Local Vars---
    integer::tid
    integer::bid
    integer::tempDir
    integer::pos
    integer::LastPowerTwo
    integer::SegmentSize
    integer::ICStart
    integer::ICEnd
    integer::IDRelative
    real(kind=KINDDF)::tempPadNum
    integer::IBox
    integer::bid0
    integer::IDSegRelative
    integer::stride
    integer::I
    integer::LeftHalf
    real(KINDDF),shared,dimension(p_BLOCKSIZE_BITONIC)::Share_KeyArray
	integer,shared,dimension(p_BLOCKSIZE_BITONIC)::Share_ValueArray
    !---Body---
    tid = (threadidx%y - 1)*blockdim%x + threadidx%x
    bid = (blockidx%y -1)*griddim%x + blockidx%x

	IBox = (bid -1)/ BlockNumEachBox_Share + 1
	bid0 = (IBox-1)*BlockNumEachBox_Share + 1
	IDSegRelative = bid - bid0

	ICStart = IDStartEnd_ForSort(bid,1)
	ICEnd = IDStartEnd_ForSort(bid,2)
	IDRelative = ICStart + tid - 1
	tempPadNum = (1 - 2 * mod(IDSegRelative/TheSize,2))*padNum

	if (ICEnd .GT. 1) then
		Share_KeyArray(tid) = tempPadNum
		if (IDRelative .LE. ICEnd) then
			Share_KeyArray(tid) = KeyArray(IDRelative)%m_Pos(1)
			Share_ValueArray(tid) = IDRelative
		end if

		Share_KeyArray(tid + p_BLOCKSIZE_BITONIC/2) = tempPadNum
		if ((IDRelative + p_BLOCKSIZE_BITONIC/2) .LE. ICEnd) then
			Share_KeyArray(tid + p_BLOCKSIZE_BITONIC/2) = KeyArray(IDRelative + p_BLOCKSIZE_BITONIC/2)%m_Pos(1)
			Share_ValueArray(tid + p_BLOCKSIZE_BITONIC/2) = IDRelative + p_BLOCKSIZE_BITONIC/2
		end if

		LastPowerTwo = 1

		SegmentSize = ICEnd - ICStart + 1

        I = 2
        DO While(I .LT. SegmentSize)

            LastPowerTwo = I

            LeftHalf = (IAND(tid-1,I/2) .ne. 0)
            LeftHalf = LeftHalf*LeftHalf   ! in PGI compiler the .true. is -1 in integer form,false is 0 in integer form

			tempDir = IEOR(mod(IDSegRelative/TheSize,2),IEOR(dir,LeftHalf))

            stride = I/2
            DO While(stride .GT. 0)
                call syncthreads()

                pos = 2*(tid - 1) - IAND(tid-1,stride -1) + 1

                call Comparetor_toApply_Shared(Share_KeyArray(pos), Share_KeyArray(pos + stride), Share_ValueArray(pos), Share_ValueArray(pos + stride), tempDir)

                stride = ISHFT(stride,-1)
            END DO

            I = ISHFT(I,1)
        END DO

        tempDir = IEOR(mod(IDSegRelative/TheSize,2),dir)

        stride = LastPowerTwo
        DO While(stride .GT. 0)
            call syncthreads()

            pos = 2*(tid - 1) - IAND(tid-1,stride -1) + 1

            call Comparetor_toApply_Shared(Share_KeyArray(pos), Share_KeyArray(pos + stride), Share_ValueArray(pos), Share_ValueArray(pos + stride), tempDir)

            stride = ISHFT(stride,-1)
        END DO

		call syncthreads()

		if (IDRelative .LE. ICEnd) then
			!KeyArray(IDRelative) = Share_KeyArray(tid)
			ValueArray(IDRelative) = Share_ValueArray(tid)
		end if

		if ((IDRelative + p_BLOCKSIZE_BITONIC / 2) .LE. ICEnd) then
			!KeyArray(IDRelative + p_BLOCKSIZE_BITONIC/2) = Share_KeyArray(tid + p_BLOCKSIZE_BITONIC/2)
			ValueArray(IDRelative + p_BLOCKSIZE_BITONIC/2) = Share_ValueArray(tid + p_BLOCKSIZE_BITONIC/2)
		end if

	end if
  end subroutine Kernel_Shared_Merge_toApply

!/*Used For Array Size less than BLOCKSIZE And is not of power 2*/
!__global__ void Kernel_Shared_Merge_Last_toApply(int BlockNumEachBox_Share,double* Dev_TestArray, int* SortedIndex, int** IDStartEnd_ForSort, int dir, int Size) {
!	int tid = threadIdx.y*blockDim.x + threadIdx.x;
!	int bid = blockIdx.y*gridDim.x + blockIdx.x;
!	int tempDir;
!	int pos;
!	int ICStart;
!	int ICEnd;
!	int ICRelative;
!	int stride;
!	int tempSegmentSize;
!	int tempICStart;
!	int tempICEnd;
!	int LastSegmentSize;
!	int LastRemindSegmentSize;
!	int tempAllSize;
!	int FlagsShift;
!	int OEFlags;
!	int FlagOne;
!	int tempLevelSeg;
!	int LRFlags;
!	int IBox;
!	int bid0;
!	int IDSegRelative;
!
!	double __shared__ Share_TestArray[BLOCKSIZE_TOAPPLY];
!	int __shared__ Share_SortedIndex[BLOCKSIZE_TOAPPLY];
!
!	IBox = bid / BlockNumEachBox_Share;
!	bid0 = IBox * BlockNumEachBox_Share;
!	IDSegRelative = bid - bid0;
!
!	ICStart = IDStartEnd_ForSort[bid][0];
!	ICEnd = IDStartEnd_ForSort[bid][1];
!	ICRelative = ICStart + tid;
!
!	if (ICEnd > 0) {
!
!		if (ICRelative <= ICEnd) {
!			Share_TestArray[tid] = Dev_TestArray[ICRelative];
!			Share_SortedIndex[tid] = SortedIndex[ICRelative];
!		}
!
!		if ((ICRelative + BLOCKSIZE_TOAPPLY / 2) <= ICEnd) {
!			Share_TestArray[tid + BLOCKSIZE_TOAPPLY / 2] = Dev_TestArray[ICRelative + BLOCKSIZE_TOAPPLY / 2];
!			Share_SortedIndex[tid + BLOCKSIZE_TOAPPLY / 2] = SortedIndex[ICRelative + BLOCKSIZE_TOAPPLY / 2];
!		}
!
!		tempDir = ((IDSegRelative / Size) % 2) ^ dir;
!		tempSegmentSize = ICEnd - ICStart + 1;
!		tempICStart = 0;
!		tempICEnd = tempICStart + tempSegmentSize / 2 - 1;
!		LastSegmentSize = tempSegmentSize;
!		LastRemindSegmentSize = LastSegmentSize - LastSegmentSize / 2;
!		tempAllSize = ICEnd - ICStart + 1;
!		OEFlags = 0;
!		LRFlags = 0;  // 0 for Left , 1 for Right
!
!		for (int LevelSeg = BLOCKSIZE_TOAPPLY / 2; LevelSeg > 0; LevelSeg >>= 1) {
!
!			__syncthreads();
!
!			FlagOne = (1 == LevelSeg) & (tempAllSize == 3);
!
!			tempLevelSeg = LevelSeg * (!FlagOne) + 2 * FlagOne;
!
!			LRFlags = (tid / tempLevelSeg) % 2;
!
!			tempAllSize = (LastSegmentSize * (LRFlags ^ 1) + LastRemindSegmentSize * (LRFlags & 1))*(!FlagOne) + tempAllSize * FlagOne;
!
!			tempSegmentSize = tempAllSize / 2;
!
!			tempICStart = tempICStart + (LastSegmentSize * (LRFlags & 1))*(!FlagOne) + FlagOne;
!			tempICEnd = tempICStart + tempSegmentSize - 1;
!
!			LastRemindSegmentSize = tempAllSize - tempAllSize / 2;
!
!			LastSegmentSize = tempSegmentSize;
!
!			FlagsShift = tempDir ^ (Share_TestArray[tempICEnd + LastRemindSegmentSize] >= Share_TestArray[tempICEnd + 1]);
!
!			OEFlags = FlagsShift & ((tempAllSize % 2) != 0);
!
!			pos = tempICStart + tid - (tid / tempLevelSeg)*tempLevelSeg;
!
!			stride = tempSegmentSize + OEFlags * (!FlagOne);
!
!			__syncthreads();
!
!			if (pos <= tempICEnd) {
!
!				Comparetor_toApply(Share_TestArray[pos], Share_TestArray[pos + stride], Share_SortedIndex[pos], Share_SortedIndex[pos + stride], tempDir);
!
!			}
!
!		}
!
!		__syncthreads();
!
!		if (ICRelative <= ICEnd) {
!			Dev_TestArray[ICRelative] = Share_TestArray[tid];
!			SortedIndex[ICRelative] = Share_SortedIndex[tid];
!		}
!		if ((ICRelative + BLOCKSIZE_TOAPPLY / 2) <= ICEnd) {
!			Dev_TestArray[ICRelative + BLOCKSIZE_TOAPPLY / 2] = Share_TestArray[tid + BLOCKSIZE_TOAPPLY / 2];
!			SortedIndex[ICRelative + BLOCKSIZE_TOAPPLY / 2] = Share_SortedIndex[tid + BLOCKSIZE_TOAPPLY / 2];
!		}
!
!	}
!}


  !***********************Used For Array Size less than BLOCKSIZE And is not of power 2*****************************
  attributes(global) subroutine Kernel_Shared_Merge_Last_toApply(BlockNumEachBox_Share,KeyArray,ValueArray,IDStartEnd_ForSort,dir,TheSize)
    !---Dummy Vars----
    integer,value::BlockNumEachBox_Share
    type(ACluster),device::KeyArray(:)
    integer,device::ValueArray(:)
    integer,device::IDStartEnd_ForSort(:,:)
    integer,value::dir
    integer,value::TheSize
    !---Local Vars---
	integer::tid
	integer::bid
	integer::tempDir
	integer::pos
	integer::ICStart
	integer::ICEnd
	integer::ICRelative
	integer::stride
	integer::tempSegmentSize
	integer::tempICStart
	integer::tempICEnd
	integer::LastSegmentSize
	integer::LastRemindSegmentSize
	integer::tempAllSize
	integer::FlagsShift
	integer::OEFlags
	integer::FlagOne
	integer::tempLevelSeg
	integer::LRFlags
	integer::IBox
	integer::bid0
	integer::IDSegRelative
    integer::LevelSeg
    integer::LogicalToInt
    real(KINDDF),shared,dimension(p_BLOCKSIZE_BITONIC)::Share_KeyArray
	integer,shared,dimension(p_BLOCKSIZE_BITONIC)::Share_ValueArray
	integer::TheValue
    !---Body---
    tid = (threadidx%y - 1)*blockdim%x + threadidx%x
    bid = (blockidx%y -1)*griddim%x + blockidx%x

	IBox = (bid -1) / BlockNumEachBox_Share + 1
	bid0 = (IBox -1) * BlockNumEachBox_Share + 1
	IDSegRelative = bid - bid0

	ICStart = IDStartEnd_ForSort(bid,1)
	ICEnd = IDStartEnd_ForSort(bid,2)
	ICRelative = ICStart + tid - 1

	if (ICEnd .GT. 1) then

		if (ICRelative .LE. ICEnd) then
            TheValue = ValueArray(ICRelative)
			Share_KeyArray(tid) = KeyArray(TheValue)%m_Pos(1)
            Share_ValueArray(tid) = TheValue
		end if

		if ((ICRelative + p_BLOCKSIZE_BITONIC/2) .LE. ICEnd) then
            TheValue = ValueArray(ICRelative + p_BLOCKSIZE_BITONIC/2)
			Share_KeyArray(tid + p_BLOCKSIZE_BITONIC/2) = KeyArray(TheValue)%m_Pos(1)
            Share_ValueArray(tid + p_BLOCKSIZE_BITONIC/2) = TheValue
		end if

        tempDir = IEOR(mod(IDSegRelative/TheSize,2),dir)
		tempSegmentSize = ICEnd - ICStart + 1
		tempICStart = 1
		tempICEnd = tempICStart + tempSegmentSize / 2 - 1
		LastSegmentSize = tempSegmentSize
		LastRemindSegmentSize = LastSegmentSize - LastSegmentSize / 2
		tempAllSize = ICEnd - ICStart + 1
		OEFlags = 0
		LRFlags = 0  ! 0 for Left , 1 for Right

        LevelSeg = p_BLOCKSIZE_BITONIC / 2
        DO While(LevelSeg .GT. 0)

			call syncthreads()

			FlagOne = ((1 .eq. LevelSeg) .AND. (tempAllSize .eq. 3))

			FlagOne = FlagOne*FlagOne   ! in PGI compiler the .true. is -1 in integer form,false is 0 in integer form

			tempLevelSeg = LevelSeg * (1-FlagOne) + 2 * FlagOne

			LRFlags = mod((tid-1)/tempLevelSeg,2)

			tempAllSize = (LastSegmentSize * IEOR(LRFlags,1) + LastRemindSegmentSize * IAND(LRFlags,1))*(1-FlagOne) + tempAllSize * FlagOne

			tempSegmentSize = tempAllSize / 2

			tempICStart = tempICStart + (LastSegmentSize * IAND(LRFlags,1))*(1-FlagOne) + FlagOne
			tempICEnd = tempICStart + tempSegmentSize - 1

			LastRemindSegmentSize = tempAllSize - tempAllSize / 2

			LastSegmentSize = tempSegmentSize

            LogicalToInt = (Share_KeyArray(tempICEnd + LastRemindSegmentSize) .GE. Share_KeyArray(tempICEnd + 1))
            LogicalToInt = LogicalToInt*LogicalToInt ! in PGI compiler the .true. is -1 in integer form,false is 0 in integer form
			FlagsShift = IEOR(tempDir,LogicalToInt)

            LogicalToInt = (mod(tempAllSize,2) .ne. 0)
            LogicalToInt = LogicalToInt*LogicalToInt ! in PGI compiler the .true. is -1 in integer form,false is 0 in integer form

			OEFlags = IAND(FlagsShift,LogicalToInt)

			pos = tempICStart + tid - ((tid -1)/ tempLevelSeg)*tempLevelSeg - 1

			stride = tempSegmentSize + OEFlags * (1-FlagOne)

			call syncthreads()

			if (pos .LE. tempICEnd) then

				call Comparetor_toApply_Shared(Share_KeyArray(pos), Share_KeyArray(pos + stride), Share_ValueArray(pos), Share_ValueArray(pos + stride), tempDir)
            end if

            LevelSeg = ISHFT(LevelSeg,-1)
		END DO

		call syncthreads()

		if (ICRelative .LE. ICEnd) then
			!KeyArray(ICRelative) = Share_KeyArray(tid)
			ValueArray(ICRelative) = Share_ValueArray(tid)
		end if
		if ((ICRelative + p_BLOCKSIZE_BITONIC / 2) .LE. ICEnd) then
			!KeyArray(ICRelative + p_BLOCKSIZE_BITONIC/2) = Share_KeyArray(tid + p_BLOCKSIZE_BITONIC/2)
			ValueArray(ICRelative + p_BLOCKSIZE_BITONIC/2) = Share_ValueArray(tid + p_BLOCKSIZE_BITONIC/2)
		end if

	end if
  end subroutine Kernel_Shared_Merge_Last_toApply


!extern "C" void ArbitraryBitonicSort_toApply(int NBox, int** IDStartEnd_ForBox_Host, int** IDStartEnd_ForBox_Dev, double* ToSortDev_ClustersPosX, int* SortedIndex, int dir, float & timerArbitraryBitonicSort) {
!	//Local Vars
!	int *OEFlags;
!	int NBGlobal;
!	int NBXGlobal;
!	int NBYGlobal;
!	int BXGlobal;
!	int BYGlobal;
!	dim3 blocksGlobal;
!	dim3 threadsGlobal;
!	int NBShared;
!	int NBXShared;
!	int NBYShared;
!	int BXShared;
!	int BYShared;
!	dim3 blocksShared;
!	dim3 threadsShared;
!	double padNum;
!	int Level;
!	int **IDStartEnd_ForSort_Host;
!	int **IDStartEnd_ForSort_Dev;
!	int *IDStartEnd_ForSort_Dev_OneDim;
!	int **AddrStartEnd_HostRecordDev;
!	int error;
!	int MaxSegmentsEachBox;
!	int tempMaxSegmentsNumEachBox;
!	int MaxSegmentsNumEachBox;
!	int MaxSegmentsNumAllBox;
!	int MaxClusterNumEachBox;
!	cudaEvent_t StartEvent;
!	cudaEvent_t StopEvent;
!
!	cudaEventCreate(&StartEvent);
!	cudaEventCreate(&StopEvent);
!
!	padNum = -1.E32;
!
!	if (0 != dir) {
!		padNum = 1.E32;
!	}
!
!
!	MaxClusterNumEachBox = 0;
!	MaxSegmentsNumEachBox = 0;
!
!	for (int IBox = 0; IBox < NBox; IBox++) {
!		MaxSegmentsEachBox = IDStartEnd_ForBox_Host[IBox][1] - IDStartEnd_ForBox_Host[IBox][0] + 1;
!		tempMaxSegmentsNumEachBox = 1;
!
!		if (MaxClusterNumEachBox < MaxSegmentsEachBox) MaxClusterNumEachBox = MaxSegmentsEachBox;
!
!		Level = 0;
!		while (MaxSegmentsEachBox > BLOCKSIZE_TOAPPLY) {
!			MaxSegmentsEachBox = MaxSegmentsEachBox - MaxSegmentsEachBox / 2;
!			tempMaxSegmentsNumEachBox <<= 1;
!			Level++;
!		}
!
!		if (MaxSegmentsNumEachBox < tempMaxSegmentsNumEachBox) MaxSegmentsNumEachBox = tempMaxSegmentsNumEachBox;
!	}
!
!	MaxSegmentsNumAllBox = MaxSegmentsNumEachBox * NBox;
!
!
!	IDStartEnd_ForSort_Host = new int*[MaxSegmentsNumAllBox];
!
!	AddrStartEnd_HostRecordDev = new int*[MaxSegmentsNumAllBox];
!
!	for (int i = 0; i < MaxSegmentsNumAllBox; i++) {
!		IDStartEnd_ForSort_Host[i] = new int[2];
!
!		for (int j = 0; j < 2; j++) {
!			IDStartEnd_ForSort_Host[i][j] = -1;
!		}
!	}
!
!	for (int IBox = 0; IBox < NBox; IBox++) {
!		MaxSegmentsEachBox = IDStartEnd_ForBox_Host[IBox][1] - IDStartEnd_ForBox_Host[IBox][0] + 1;
!
!		Level = 0;
!		while (MaxSegmentsEachBox > BLOCKSIZE_TOAPPLY) {
!			MaxSegmentsEachBox = MaxSegmentsEachBox - MaxSegmentsEachBox / 2;
!			Level++;
!		}
!
!		FillTheSEArray_toApply(Level, MaxSegmentsNumEachBox,IBox, IDStartEnd_ForBox_Host[IBox][0], IDStartEnd_ForBox_Host[IBox][1], 0, IDStartEnd_ForSort_Host);
!	}
!
!	cudaMalloc((void**)&OEFlags, sizeof(int)*MaxSegmentsNumAllBox);
!
!	error = cudaMalloc((void**)&IDStartEnd_ForSort_Dev, MaxSegmentsNumAllBox * sizeof(int*));
!
!
!	for (int i = 0; i < MaxSegmentsNumAllBox; i++) {
!		error = cudaMalloc((void**)&IDStartEnd_ForSort_Dev_OneDim, 2 * sizeof(int));
!
!		cudaMemcpy(IDStartEnd_ForSort_Dev_OneDim, IDStartEnd_ForSort_Host[i], 2 * sizeof(int), cudaMemcpyHostToDevice);
!
!		AddrStartEnd_HostRecordDev[i] = IDStartEnd_ForSort_Dev_OneDim;
!	}
!
!	cudaMemcpy(IDStartEnd_ForSort_Dev, AddrStartEnd_HostRecordDev, MaxSegmentsNumAllBox * sizeof(int*), cudaMemcpyHostToDevice);
!
!
!	BXGlobal = BLOCKSIZE_TOAPPLY;
!	BYGlobal = 1;
!	NBGlobal = MaxSegmentsNumAllBox / 2;
!	NBXGlobal = NBGlobal;
!	NBYGlobal = 1;
!	blocksGlobal = dim3(NBXGlobal, NBYGlobal, 1);
!	threadsGlobal = dim3(BXGlobal, BYGlobal, 1);
!
!	BXShared = BLOCKSIZE_TOAPPLY / 2;
!	BYShared = 1;
!	NBShared = MaxSegmentsNumAllBox;
!	NBXShared = NBShared;
!	NBYShared = 1;
!	blocksShared = dim3(NBXShared, NBYShared, 1);
!	threadsShared = dim3(BXShared, BYShared, 1);
!
!	cudaDeviceSynchronize();
!
!	cudaEventRecord(StartEvent, 0);
!
!	if (MaxClusterNumEachBox <= BLOCKSIZE_TOAPPLY) {
!		Kernel_Shared_ArbitraryBitonicSort_toApply << <blocksShared, threadsShared >> > (ToSortDev_ClustersPosX, SortedIndex, IDStartEnd_ForSort_Dev, dir, padNum);
!	}
!	else {
!
!		Kernel_Shared_Merge_toApply << <blocksShared, threadsShared >> > (MaxSegmentsNumEachBox,ToSortDev_ClustersPosX, SortedIndex, IDStartEnd_ForSort_Dev, dir, padNum, 1);
!
!		for (int Size = 2; Size <= MaxSegmentsNumEachBox; Size <<= 1) {
!
!			for (int Stride = Size / 2; Stride >= 0; Stride >>= 1) {
!
!				if (Stride >= 1) {
!
!					Kernel_GlobalMerge_Pre_toApply << <blocksGlobal, 1 >> > (MaxSegmentsNumEachBox/2,Size, Stride, IDStartEnd_ForSort_Dev, ToSortDev_ClustersPosX, dir, OEFlags);
!
!					Kernel_GlobalMerge_toApply << <blocksGlobal, threadsGlobal >> > (MaxSegmentsNumEachBox/2,Size, Stride, IDStartEnd_ForSort_Dev, ToSortDev_ClustersPosX, SortedIndex, dir, OEFlags);
!				}
!				else {
!
!					Kernel_Shared_Merge_Last_toApply << <blocksShared, threadsShared >> > (MaxSegmentsNumEachBox,ToSortDev_ClustersPosX, SortedIndex, IDStartEnd_ForSort_Dev, dir, Size);
!
!					break;
!				}
!
!			}
!
!		}
!	}
!
!	cudaEventRecord(StopEvent, 0);
!
!	cudaEventSynchronize(StopEvent);
!
!	cudaEventElapsedTime(&timerArbitraryBitonicSort, StartEvent, StopEvent);
!
!	cudaDeviceSynchronize();
!
!	cudaEventDestroy(StartEvent);
!	cudaEventDestroy(StopEvent);
!
!	cudaFree(OEFlags);
!}

  recursive subroutine FillTheSEArray_ForBitonicSort(Level,MaxSegmentsNumEachBox,IBox,Left,Right,TheIndex,SEArray)
    implicit none
    !---Dummy Vars---
    integer::Level
    integer::MaxSegmentsNumEachBox
    integer::IBox
    integer::Left
    integer::Right
    integer::TheIndex
    integer,dimension(:,:),allocatable::SEArray
    !---Local Vars---
	integer::trueIndex
    !---Body---
	if (0 .eq. Level .or. Left .eq. Right) then
		trueIndex = (IBox-1)*MaxSegmentsNumEachBox + TheIndex + 1

		SEArray(trueIndex,1) = Left

		SEArray(trueIndex,2) = Right
		return
	end if

	call FillTheSEArray_ForBitonicSort(Level-1, MaxSegmentsNumEachBox, IBox, Left, Left + (Right - Left + 1)/2 - 1, TheIndex*2, SEArray)
	call FillTheSEArray_ForBitonicSort(Level-1, MaxSegmentsNumEachBox, IBox, Left + (Right - Left + 1)/2, Right, TheIndex*2 + 1, SEArray)

	return
  end subroutine FillTheSEArray_ForBitonicSort

  !**************************************************
  subroutine InitBitionicSort(this,MultiBox,dir,IDStartEnd_ForBox_Host)
    implicit none
    !---Dummy Vars---
    CLASS(BitionicSort)::this
    integer,intent(in)::MultiBox
    integer,intent(in)::dir
    integer,dimension(:,:),allocatable::IDStartEnd_ForBox_Host
    !---Local Vars---
    integer::IBox
    integer::tempMaxSegmentsNumEachBox
    integer::tempNCEachBox
    integer::I
    integer::J
    integer::Level
    integer::BXGlobal
	integer::BYGlobal
	integer::NBGlobal
	integer::NBXGlobal
	integer::NBYGlobal
	integer::BXShared
	integer::BYShared
	integer::NBShared
	integer::NBXShared
	integer::NBYShared
	integer::TotalNC
    !---Body---
    if(dir .ne. p_Sort_Descending .AND. dir .ne. p_Sort_Ascending) then
        write(*,*) "MCPSCUERROR: The sort direction can only be Descending: ",p_Sort_Descending
        write(*,*) "or Ascending: ",p_Sort_Ascending
        pause
        stop
    end if
    this%dir = dir

    this%padNum = 1.D32
	if (p_Sort_Descending .eq. dir) then
		this%padNum = -1.D32
	end if

	this%MaxClusterNumEachBox = 0
	this%MaxSegmentsNumEachBox = 0

    DO IBox = 1,MultiBox
        tempNCEachBox = IDStartEnd_ForBox_Host(IBox,2) - IDStartEnd_ForBox_Host(IBox,1) + 1

        tempMaxSegmentsNumEachBox = 1

		if (this%MaxClusterNumEachBox .LT. tempNCEachBox) then
            this%MaxClusterNumEachBox = tempNCEachBox
        end if

		DO while (tempNCEachBox .GT. p_BLOCKSIZE_BITONIC)
			tempNCEachBox = tempNCEachBox - tempNCEachBox/2

			tempMaxSegmentsNumEachBox = ISHFT(tempMaxSegmentsNumEachBox,1)
		END DO

		if (this%MaxSegmentsNumEachBox .LT. tempMaxSegmentsNumEachBox) then
            this%MaxSegmentsNumEachBox = tempMaxSegmentsNumEachBox
        end if
    END DO

	this%MaxSegmentsNumAllBox = this%MaxSegmentsNumEachBox*MultiBox

    call AllocateArray_Host(this%IDStartEnd_ForSort_Host,this%MaxSegmentsNumAllBox,2,"this%IDStartEnd_ForSort_Host")

    DO I = 1,this%MaxSegmentsNumAllBox
        DO J = 1,2
            this%IDStartEnd_ForSort_Host(I,J) = -1
        END DO
    END DO

    DO IBox=1,MultiBox
        tempNCEachBox = IDStartEnd_ForBox_Host(IBox,2) - IDStartEnd_ForBox_Host(IBox,1) + 1

		Level = 0
        DO while(tempNCEachBox .GT. p_BLOCKSIZE_BITONIC)
            tempNCEachBox = tempNCEachBox - tempNCEachBox/2
            Level = Level + 1
        END DO

		call FillTheSEArray_ForBitonicSort(Level,this%MaxSegmentsNumEachBox,IBox,IDStartEnd_ForBox_Host(IBox,1), IDStartEnd_ForBox_Host(IBox,2), 0, this%IDStartEnd_ForSort_Host)

    END DO

    call AllocateArray_GPU(this%IDStartEnd_ForSort_Dev,this%MaxSegmentsNumAllBox,2,"this%IDStartEnd_ForSort_Dev")

    this%IDStartEnd_ForSort_Dev = this%IDStartEnd_ForSort_Host

    call AllocateArray_GPU(this%OEFlags_Dev,this%MaxSegmentsNumAllBox,"this%OEFlags_Dev")

    if(IDStartEnd_ForBox_Host(MultiBox,2) .GT. 0) then
        TotalNC = IDStartEnd_ForBox_Host(MultiBox,2) - IDStartEnd_ForBox_Host(1,1) + 1
    else
        TotalNC = 0
    end if

    call AllocateArray_GPU(this%SortedIndex_Dev,TotalNC,"this%SortedIndex_Dev")

	BXGlobal = p_BLOCKSIZE_BITONIC
	BYGlobal = 1
	NBGlobal = this%MaxSegmentsNumAllBox/2
	NBXGlobal = NBGlobal
	NBYGlobal = 1
	this%blocksGlobal = dim3(NBXGlobal, NBYGlobal, 1)
	this%threadsGlobal = dim3(BXGlobal, BYGlobal, 1)

	BXShared = p_BLOCKSIZE_BITONIC / 2
	BYShared = 1
	NBShared = this%MaxSegmentsNumAllBox
	NBXShared = NBShared
	NBYShared = 1
	this%blocksShared = dim3(NBXShared, NBYShared, 1)
	this%threadsShared = dim3(BXShared, BYShared, 1)

    this%HasInitedFlag = .true.
    return
  end subroutine InitBitionicSort

  !**********************************************************************************
  subroutine Clean_BitionicSort(this)
    implicit none
    !---Dummy Vars----
    CLASS(BitionicSort)::this
    !---Body---
    if(allocated(this%IDStartEnd_ForSort_Host)) then
        deallocate(this%IDStartEnd_ForSort_Host)
    end if

    if(allocated(this%IDStartEnd_ForSort_Dev)) then
        deallocate(this%IDStartEnd_ForSort_Dev)
    end if

    if(allocated(this%OEFlags_Dev)) then
        deallocate(this%OEFlags_Dev)
    end if

    if(allocated(this%SortedIndex_Dev)) then
        deallocate(this%SortedIndex_Dev)
    end if

	this%MaxSegmentsNumEachBox = 0
	this%MaxSegmentsNumAllBox = 0
	this%MaxClusterNumEachBox = 0
    this%dir = p_Sort_Ascending
    this%padNum = 1.D32
    this%HasInitedFlag = .false.

    return
  end subroutine

  !**********************************************************************************
  subroutine CleanBitionicSort(this)
    implicit none
    !---Dummy Vars----
    type(BitionicSort)::this
    !---Body---
    call this%Clean()

    return
  end subroutine


  subroutine CheckSort_Test(MulitBox,MaxSegNumEachBox,IDSEArray_ForSort_Dev,DevClusters,SortedIndex_Dev)
    implicit none
    !---Dummy Vars---
    integer::MulitBox
    integer::MaxSegNumEachBox
    integer,device,dimension(:,:),allocatable::IDSEArray_ForSort_Dev
    type(ACluster),device,dimension(:),allocatable::DevClusters
    integer,device,dimension(:),allocatable::SortedIndex_Dev
    !---Local Vars---
    type(ACluster),dimension(:),allocatable::HostClusters
    integer,dimension(:,:),allocatable::Host_IDSEArray
    integer::NSize
    integer::IBox
    integer::ICFrom
    integer::ICTo
    integer::IC
    integer::ISeg
    integer,dimension(:),allocatable::Host_MySortedIndexArray
    !---Body---
    NSize = size(DevClusters)

    call AllocateArray_Host(HostClusters,NSize,"HostClusters")
    HostClusters = DevClusters

    call AllocateArray_Host(Host_IDSEArray,MulitBox*MaxSegNumEachBox,2,"Host_IDSEArray")

    Host_IDSEArray = IDSEArray_ForSort_Dev

    call AllocateArray_Host(Host_MySortedIndexArray,NSize,"Host_MySortedIndexArray")
    Host_MySortedIndexArray = SortedIndex_Dev

    write(*,*) "MulitBox*MaxSegNumEachBox*2",MulitBox*MaxSegNumEachBox*2
    write(*,*) size(IDSEArray_ForSort_Dev)

    DO IBox = 1,MulitBox

        if(IBox .eq. 1) then
            write(*,*) "******************IBox********************",IBox
            DO ISeg = (IBox-1)*MaxSegNumEachBox +1,IBox*MaxSegNumEachBox

                ICFrom = Host_IDSEArray(ISeg,1)
                ICTo = Host_IDSEArray(ISeg,2)

                write(*,*) "ISeg: ",ISeg,ICFrom,ICTo
                if(ICTo .GT. 0) then
                    DO IC = ICFrom,ICTo
                        write(*,*) IC,Host_MySortedIndexArray(IC),HostClusters(Host_MySortedIndexArray(IC))%m_POS(1)
                    END DO
                end if
            END DO
        end if

    END DO

    call DeAllocateArray_Host(HostClusters,"HostClusters")
    call DeAllocateArray_Host(Host_IDSEArray,"Host_IDSEArray")
    call DeAllocateArray_Host(Host_MySortedIndexArray,"Host_MySortedIndexArray")

    return
  end subroutine CheckSort_Test

  !**********************************************************************************
  subroutine ArbitraryBitonicSort_toApply(this,NBox, KeyArray)
    implicit none
    !---Dummy Vars----
    CLASS(BitionicSort)::this
    integer,intent(in)::NBox
    type(ACluster),device,dimension(:),allocatable::KeyArray
    !---Local Vars---
	integer::TheSize
	integer::Stride
    !---Body---

	if (this%MaxClusterNumEachBox .LE. p_BLOCKSIZE_BITONIC) then
		call Kernel_Shared_ArbitraryBitonicSort_toApply<<<this%blocksShared,this%threadsShared>>>(KeyArray, this%SortedIndex_Dev,this%IDStartEnd_ForSort_Dev, this%dir, this%padNum)
	else

		call Kernel_Shared_Merge_toApply<<<this%blocksShared,this%threadsShared>>>(this%MaxSegmentsNumEachBox,KeyArray,this%SortedIndex_Dev,this%IDStartEnd_ForSort_Dev,this%dir,this%padNum,1)


!        write(*,*) "****************Kernel_Shared_Merge_toApply*************************"
!        call CheckSort_Test(NBox,this%MaxSegmentsNumEachBox,this%IDStartEnd_ForSort_Dev,KeyArray,this%SortedIndex_Dev)
!        pause


        TheSize = 2
        DO While(TheSize .LE. this%MaxSegmentsNumEachBox)

            Stride = TheSize/2
            Do While(Stride .GE. 0)
                if(Stride .GE. 1) then

                    call Kernel_GlobalMerge_Pre_toApply<<<this%blocksGlobal,1>>>(this%MaxSegmentsNumEachBox/2,TheSize, Stride, this%IDStartEnd_ForSort_Dev,KeyArray,this%SortedIndex_Dev,this%dir,this%OEFlags_Dev)


					call Kernel_GlobalMerge_toApply<<<this%blocksGlobal,this%threadsGlobal>>>(this%MaxSegmentsNumEachBox/2,TheSize, Stride,this%IDStartEnd_ForSort_Dev,KeyArray,this%SortedIndex_Dev,this%dir,this%OEFlags_Dev)


!					        write(*,*) "****************Kernel_GlobalMerge_toApply*************************",TheSize,Stride
!                            call CheckSort_Test(NBox,this%MaxSegmentsNumEachBox,this%IDStartEnd_ForSort_Dev,KeyArray,this%SortedIndex_Dev)
!                            pause

                else

                    call Kernel_Shared_Merge_Last_toApply<<<this%blocksShared,this%threadsShared>>>(this%MaxSegmentsNumEachBox,KeyArray,this%SortedIndex_Dev,this%IDStartEnd_ForSort_Dev,this%dir,TheSize)


!                            write(*,*) "****************Kernel_Shared_Merge_Last_toApply*************************",TheSize,Stride
!                            call CheckSort_Test(NBox,this%MaxSegmentsNumEachBox,this%IDStartEnd_ForSort_Dev,KeyArray,this%SortedIndex_Dev)
!                            pause
                    exit
                end if

                Stride = ISHFT(Stride,-1)
            End Do

            TheSize = ISHFT(TheSize,1)
        END DO
    end if

  end subroutine ArbitraryBitonicSort_toApply

end module MCLIB_Utilities_GPU
